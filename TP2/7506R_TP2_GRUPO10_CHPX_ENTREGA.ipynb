{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U78vmVS4KSSj"
      },
      "source": [
        "# <center> Trabajo Practico 2 </center>\n",
        "### <center> Grupo 10 </center>\n",
        "## Integrantes:\n",
        "#### Alan Richmond\n",
        "#### Flavian Ferré\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqfbg4r8KSSk"
      },
      "source": [
        "# Importaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algunas instalaciones\n",
        "\n",
        "A ejecutar solo si no dispone de los paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9IqgNJhc6J3",
        "outputId": "1dceea31-93ba-4d75-9082-f8180c14af14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVjmO_U2hSaA",
        "outputId": "f9ce8e97-8f3f-48d5-d283-dd14290a6722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: es_core_news_sm in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from es_core_news_sm) (3.1.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (24.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2024.6.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnbSDgK_KSSl"
      },
      "source": [
        "## Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BGWufC9JKSSl"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import stop_words\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import BatchNormalization, Dense, Dropout, Input, TextVectorization\n",
        "from keras.metrics import F1Score\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adadelta, Adam, RMSprop\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, make_scorer, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x1MsF7hKSSm"
      },
      "source": [
        "## Conjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MTohTcjkKSSm"
      },
      "outputs": [],
      "source": [
        "# Cargar los datasets del Kaggle\n",
        "conjunto_train = pd.read_csv('Datasets/train.csv')\n",
        "conjunto_test = pd.read_csv('Datasets/test.csv')\n",
        "sample_solution = pd.read_csv('Datasets/sample_solution.csv')\n",
        "\n",
        "# StopWords que va a servir a lematizar\n",
        "stop_words_es = stop_words.get_stop_words('es')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okCsC7nBb8r_"
      },
      "source": [
        "## Train_test_split\n",
        "\n",
        "No se debe ejecutar de nuevo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_HPSAAyUb8r_"
      },
      "outputs": [],
      "source": [
        "# Dividir los conjuntos\n",
        "X = conjunto_train['review_es']\n",
        "y = conjunto_train['sentimiento'].map({'positivo': 1, 'negativo': 0})\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Exportacion de esos nuevos conjuntos\n",
        "X_train.to_csv('Datasets/X_train.csv')\n",
        "X_test.to_csv('Datasets/X_test.csv')\n",
        "y_train.to_csv('Datasets/y_train.csv')\n",
        "y_test.to_csv('Datasets/y_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loZxYjlCb8sA"
      },
      "source": [
        "## Lematizacion\n",
        "\n",
        "No se debe ejecutar de nuevo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000    La mayor virtud de esta película es su existen...\n",
              "60001    No soy un experto cinéfilo, pero pocas veces m...\n",
              "60002    Si no eres un incondicional del humor estilo T...\n",
              "60003    No sé qué está pasando, si la gente se deja ll...\n",
              "60004    Pero cuando amanece,y me quedo solo,siento en ...\n",
              "                               ...                        \n",
              "68594    Buena no, lo siguiente. Por fin un film serio ...\n",
              "68595    Me esperaba mucho, pero que mucho, más.Guión m...\n",
              "68596    De mal cuerpo como sensación al finalizar, de ...\n",
              "68597    Los que han añadido comentarios os lo han dich...\n",
              "68598    Fui a ver esta película de cine con entusiasmo...\n",
              "Name: review_es, Length: 8599, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transformacion del conjunto test\n",
        "test = conjunto_test.set_index('ID')\n",
        "test.index.name = None\n",
        "test = test['review_es']\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BedCsafoMmVb",
        "outputId": "99fed4ea-7806-439e-86f8-e3288096f278"
      },
      "outputs": [],
      "source": [
        "# Lematizacion\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in doc if token.is_alpha])\n",
        "\n",
        "# Exportaciones\n",
        "conjunto_test_processed = test.apply(preprocess_text)\n",
        "X_train_processed = X_train.apply(preprocess_text)\n",
        "X_test_processed = X_test.apply(preprocess_text)\n",
        "conjunto_test_processed.to_csv('Datasets/conjunto_test_processed.csv')\n",
        "X_train_processed.to_csv('Datasets/X_train_processed.csv')\n",
        "X_test_processed.to_csv('Datasets/X_test_processed.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me4CIP7UKSSm"
      },
      "source": [
        "# 1. Bayes Naïve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMbj9XKKb8sB"
      },
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Hr0mPk1b8sB"
      },
      "outputs": [],
      "source": [
        "# Datasets a cargar\n",
        "X_train = pd.read_csv('Datasets/X_train.csv', index_col=0)['review_es']\n",
        "X_test = pd.read_csv('Datasets/X_test.csv', index_col=0)['review_es']\n",
        "y_train = pd.read_csv('Datasets/y_train.csv', index_col=0)['sentimiento']\n",
        "y_test = pd.read_csv('Datasets/y_test.csv', index_col=0)['sentimiento']\n",
        "\n",
        "# Esos son los que fueron lematizados\n",
        "X_train_processed = pd.read_csv('Datasets/X_train_processed.csv', index_col=0)['review_es']\n",
        "X_test_processed = pd.read_csv('Datasets/X_test_processed.csv', index_col=0)['review_es']\n",
        "conjunto_test_processed = pd.read_csv('Datasets/conjunto_test_processed.csv', index_col=0)['review_es']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBy-DEPjb8sB"
      },
      "source": [
        "## Vectorizacion de las críticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAzRpaXRb8sB"
      },
      "source": [
        "Vamos a hacer diferentes vectorizaciones para elegir la mejor :\n",
        "- Vect_1 : TFIDF Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_2 : TFIDF Vectorizer con lematizacion y con hiperparametros afinados\n",
        "- Vect_3 : Count Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_4 : Count Vectorizer con lematizacion y con hiperparametros afinados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kFLcY1Rlb8sB"
      },
      "outputs": [],
      "source": [
        "best_configs = []\n",
        "\n",
        "# Creacion de las diferentes combinaciones de hiperparametros\n",
        "min_dfs = [1, 2, 3, 5, 8, 10, 12, 15]\n",
        "ngram_ranges = [(1, 2), (1, 3), (1, 4)]\n",
        "configs = [{'min_df': min_df, 'ngram_range': ngram_range} for min_df in min_dfs for ngram_range in ngram_ranges]\n",
        "\n",
        "# Model de referencia para encontrar la vectorizacion optimizada\n",
        "nb_old_model = joblib.load('Modelos/bn_model_2024-06-12.joblib')\n",
        "\n",
        "def test_config(config, X_train, vectorizer):\n",
        "    vect = vectorizer(stop_words=stop_words_es, **config)\n",
        "    X_train_vect = vect.fit_transform(X_train)\n",
        "\n",
        "    # Aca tenemos problemas con ese parametro cuando cargamos el modelo, asi ponemos True cada vez\n",
        "    if hasattr(nb_old_model, 'force_alpha') and nb_old_model.force_alpha not in [True, False]:\n",
        "        nb_old_model.force_alpha = True\n",
        "    \n",
        "    score = cross_val_score(nb_old_model, X_train_vect, y_train, cv=10, scoring='f1_macro')\n",
        "    return round(score.mean(), 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpfPKzMb8sB"
      },
      "source": [
        "### Vect_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIXZREgHb8sB",
        "outputId": "43941f05-7b77-4892-e1e2-a92bc3fd3419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_1 : {'min_df': 2, 'ngram_range': (1, 3)}\n",
            "Mejor F1-Score Vect_1 : 0.886926\n"
          ]
        }
      ],
      "source": [
        "best_score_1 = 0\n",
        "best_config_1 = None\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train, TfidfVectorizer)\n",
        "    if score > best_score_1:\n",
        "        best_score_1 = score\n",
        "        best_config_1 = config\n",
        "\n",
        "best_configs.append([best_score_1, best_config_1, False, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_1 :\", best_config_1)\n",
        "print(\"Mejor F1-Score Vect_1 :\", best_score_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7YhQIROb8sC"
      },
      "source": [
        "### Vect_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flRbj1Rib8sC",
        "outputId": "0579b851-8a63-4f3a-d14e-9549e9f4683f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_2 : {'min_df': 2, 'ngram_range': (1, 4)}\n",
            "Mejor F1-Score Vect_2 : 0.882998\n"
          ]
        }
      ],
      "source": [
        "best_score_2 = 0\n",
        "best_config_2 = None\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_processed, TfidfVectorizer)\n",
        "    if score > best_score_2:\n",
        "        best_score_2 = score\n",
        "        best_config_2 = config\n",
        "\n",
        "best_configs.append([best_score_2, best_config_2, True, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_2 :\", best_config_2)\n",
        "print(\"Mejor F1-Score Vect_2 :\", best_score_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mv8nrTrb8sD"
      },
      "source": [
        "### Vect_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxxsY9-Vb8sD",
        "outputId": "0d997d82-106a-4372-e83c-a189de51dde8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_3 : {'min_df': 2, 'ngram_range': (1, 4)}\n",
            "Mejor F1-Score Vect_3 : 0.878272\n"
          ]
        }
      ],
      "source": [
        "best_score_3 = 0\n",
        "best_config_3 = None\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train, CountVectorizer)\n",
        "    if score > best_score_3:\n",
        "        best_score_3 = score\n",
        "        best_config_3 = config\n",
        "\n",
        "best_configs.append([best_score_3, best_config_3, False, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_3 :\", best_config_3)\n",
        "print(\"Mejor F1-Score Vect_3 :\", best_score_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWM0VC0Ab8sD"
      },
      "source": [
        "### Vect_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEx0kRYAb8sD",
        "outputId": "c55d22b6-9a02-41fc-f57e-3adc9ba12b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_4 : {'min_df': 2, 'ngram_range': (1, 4)}\n",
            "Mejor F1-Score Vect_4 : 0.874868\n"
          ]
        }
      ],
      "source": [
        "best_score_4 = 0\n",
        "best_config_4 = None\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_processed, CountVectorizer)\n",
        "    if score > best_score_4:\n",
        "        best_score_4 = score\n",
        "        best_config_4 = config\n",
        "\n",
        "best_configs.append([best_score_4, best_config_4, True, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_4 :\", best_config_4)\n",
        "print(\"Mejor F1-Score Vect_4 :\", best_score_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQl6eS0yb8sD"
      },
      "source": [
        "### Mejor Vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "vOoaHsbyb8sD",
        "outputId": "6e25f318-3e71-4c51-93da-6ee80a0da995"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Config</th>\n",
              "      <th>Lematizacion</th>\n",
              "      <th>Tipo de vectorizacion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.886926</td>\n",
              "      <td>{'min_df': 2, 'ngram_range': (1, 3)}</td>\n",
              "      <td>False</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.882998</td>\n",
              "      <td>{'min_df': 2, 'ngram_range': (1, 4)}</td>\n",
              "      <td>True</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.878272</td>\n",
              "      <td>{'min_df': 2, 'ngram_range': (1, 4)}</td>\n",
              "      <td>False</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.874868</td>\n",
              "      <td>{'min_df': 2, 'ngram_range': (1, 4)}</td>\n",
              "      <td>True</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Score                                Config  Lematizacion  \\\n",
              "0  0.886926  {'min_df': 2, 'ngram_range': (1, 3)}         False   \n",
              "1  0.882998  {'min_df': 2, 'ngram_range': (1, 4)}          True   \n",
              "2  0.878272  {'min_df': 2, 'ngram_range': (1, 4)}         False   \n",
              "3  0.874868  {'min_df': 2, 'ngram_range': (1, 4)}          True   \n",
              "\n",
              "  Tipo de vectorizacion  \n",
              "0                 TFIDF  \n",
              "1                 TFIDF  \n",
              "2                 Count  \n",
              "3                 Count  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_configs_df = pd.DataFrame(data=best_configs, columns=[\"Score\", \"Config\", \"Lematizacion\", \"Tipo de vectorizacion\"])\n",
        "best_configs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRLe2dhBb8sE",
        "outputId": "b1ba9ef8-9b38-4d81-c638-924f50aca3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.886926 - Configuracion: {'min_df': 2, 'ngram_range': (1, 3)} - Lematizacion: False - Tipo: TFIDF\n"
          ]
        }
      ],
      "source": [
        "best_index = best_configs_df['Score'].idxmax()\n",
        "\n",
        "best_score = best_configs_df.loc[best_index, 'Score']\n",
        "best_config = best_configs_df.loc[best_index, 'Config']\n",
        "bool_lemma = best_configs_df.loc[best_index, 'Lematizacion']\n",
        "type_vect = best_configs_df.loc[best_index, 'Tipo de vectorizacion']\n",
        "\n",
        "print(f\"Score: {best_score} - Configuracion: {best_config} - Lematizacion: {bool_lemma} - Tipo: {type_vect}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dcQU3ikwb8sF"
      },
      "outputs": [],
      "source": [
        "if bool_lemma :\n",
        "    # Si vamos a utilizar la lematizacion\n",
        "    X_train = X_train_processed\n",
        "    X_test = X_test_processed\n",
        "if type_vect == \"TFIDF\":\n",
        "    vect = TfidfVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Count\":\n",
        "    vect = CountVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Hashing\":\n",
        "    vect = HashingVectorizer(stop_words=stop_words_es, **best_config)\n",
        "\n",
        "X_train_vect = vect.fit_transform(X_train)\n",
        "X_test_vect = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFzQhgT7dK98"
      },
      "source": [
        "## Busqueda de los hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvU_80fVb8sF",
        "outputId": "bcb3b483-0ea6-42db-c639-104fb0ba7b5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parametros: {'alpha': 0.2}\n",
            "Mejor F1 Score: 0.886841592387636\n",
            "Mejores parametros (afinados): {'alpha': 0.22}\n",
            "Mejor F1 Score (afinados): 0.8870333497774672\n"
          ]
        }
      ],
      "source": [
        "# Los hiperparametros a probar\n",
        "param_distributions = {\n",
        "    'alpha': [0.1, 0.2, 0.5, 0.8, 1.0, 1.5, 2.0, 3.0, 5.0]\n",
        "}\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=nb_model, param_distributions=param_distributions, cv=5, n_iter=20, scoring=f1_scorer)\n",
        "random_search.fit(X_train_vect, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "print(f'Mejores parametros: {best_params}')\n",
        "print(f'Mejor F1 Score: {best_score}')\n",
        "\n",
        "# Vamos a afinar el parametro elegido\n",
        "best_params = random_search.best_params_\n",
        "param_grid = {\n",
        "    'alpha': [best_params['alpha'] - 0.05, best_params['alpha'] - 0.02, best_params['alpha'], best_params['alpha'] + 0.02, best_params['alpha'] + 0.05]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=nb_model, param_grid=param_grid, cv=5, scoring=f1_scorer)\n",
        "grid_search.fit(X_train_vect, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f'Mejores parametros (afinados): {best_params}')\n",
        "print(f'Mejor F1 Score (afinados): {best_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rDomjk1dNVG",
        "outputId": "b40d9ac0-8bfa-46b2-a9ee-b0a123d4524a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8864\n",
            "Precision: 0.8778315585672798\n",
            "Recall: 0.8997817027187934\n",
            "F1 Score: 0.8886711093688748\n"
          ]
        }
      ],
      "source": [
        "best_nb_model = grid_search.best_estimator_\n",
        "best_nb_model.fit(X_train_vect, y_train)\n",
        "y_pred = best_nb_model.predict(X_test_vect)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72GV_j_YdOeF"
      },
      "source": [
        "## Conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0P-gYduKdT_g",
        "outputId": "d6658a86-e790-49ee-f1eb-d25d92864919"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    negativo\n",
              "2     60002    negativo\n",
              "3     60003    positivo\n",
              "4     60004    negativo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    negativo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if bool_lemma:\n",
        "    # Si utilizamos el conjunto con lematizacion\n",
        "    conjunto_test = conjunto_test_processed.copy()\n",
        "    X_conjunto_test = vect.transform(conjunto_test)\n",
        "    \n",
        "else :\n",
        "    conjunto_test = conjunto_test.set_index(conjunto_test['ID'])\n",
        "    X_conjunto_test = vect.transform(conjunto_test['review_es'])\n",
        "\n",
        "pred_test = best_nb_model.predict(X_conjunto_test)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyx0QpVUdWW-"
      },
      "source": [
        "## Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tCc4nGH0dYx7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/bn_model_2024-06-25.joblib']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Bayes_Naïve_{current_date}.csv\", index=False)\n",
        "\n",
        "joblib.dump(best_nb_model, f'Modelos/bn_model_{current_date}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWBhPxVRKSSm"
      },
      "source": [
        "# 2. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGRmfphob8sJ"
      },
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "F3TZG_ufb8sJ"
      },
      "outputs": [],
      "source": [
        "# Datasets a cargar\n",
        "X_train = pd.read_csv('Datasets/X_train.csv', index_col=0)['review_es']\n",
        "X_test = pd.read_csv('Datasets/X_test.csv', index_col=0)['review_es']\n",
        "y_train = pd.read_csv('Datasets/y_train.csv', index_col=0)['sentimiento']\n",
        "y_test = pd.read_csv('Datasets/y_test.csv', index_col=0)['sentimiento']\n",
        "\n",
        "# Esos son los que fueron lematizados\n",
        "X_train_processed = pd.read_csv('Datasets/X_train_processed.csv', index_col=0)['review_es']\n",
        "X_test_processed = pd.read_csv('Datasets/X_test_processed.csv', index_col=0)['review_es']\n",
        "conjunto_test_processed = pd.read_csv('Datasets/conjunto_test_processed.csv', index_col=0)['review_es']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RvVJtt0cnFs"
      },
      "source": [
        "## Vectorizacion de las críticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh7sSIRdb8sK"
      },
      "source": [
        "Vamos a hacer diferentes vectorizaciones para elegir la mejor :\n",
        "- Vect_1 : TFIDF Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_2 : TFIDF Vectorizer con lematizacion y con hiperparametros afinados\n",
        "- Vect_3 : Count Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_4 : Count Vectorizer con lematizacion y con hiperparametros afinados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "X5KgwWNBb8sK"
      },
      "outputs": [],
      "source": [
        "best_configs = []\n",
        "\n",
        "# Creacion de las diferentes combinaciones de hiperparametros\n",
        "min_dfs = [1, 2, 3, 4, 5, 8, 10, 15]\n",
        "ngram_ranges = [(1, 2), (1, 3), (1, 4)]\n",
        "configs = [{'min_df': min_df, 'ngram_range': ngram_range} for min_df in min_dfs for ngram_range in ngram_ranges]\n",
        "\n",
        "# Model de referencia para encontrar la vectorizacion optimizada\n",
        "rf_old_model = joblib.load('Modelos/rf_model_2024-06-15.joblib')\n",
        "\n",
        "def test_config(config, X_train, y_train, vectorizer):\n",
        "    vect = vectorizer(stop_words=stop_words_es, **config)\n",
        "    X_train_vect = vect.fit_transform(X_train)\n",
        "    score = cross_val_score(rf_old_model, X_train_vect, y_train, cv=10, scoring='f1_macro')\n",
        "    return round(score.mean(), 6)\n",
        "\n",
        "# Funcion para guardar un sample de nuestros datasets\n",
        "def sample_df(X, y):\n",
        "    sample_size = int(0.1 * X.shape[0])\n",
        "    sample_indices = np.random.choice(X.shape[0], size=sample_size, replace=False)\n",
        "    X_sampled = X.iloc[sample_indices]\n",
        "    y_sampled = y.iloc[sample_indices]\n",
        "    return X_sampled, y_sampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ntHw0sb8sK"
      },
      "source": [
        "### Vect_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lPyH26rb8sK",
        "outputId": "b3ef487a-cfbf-4a70-a9b5-6983050017d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_1 : {'min_df': 1, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_1 : 0.817644\n"
          ]
        }
      ],
      "source": [
        "best_score_1 = 0\n",
        "best_config_1 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, TfidfVectorizer)\n",
        "    if score > best_score_1:\n",
        "        best_score_1 = score\n",
        "        best_config_1 = config\n",
        "\n",
        "best_configs.append([best_score_1, best_config_1, False, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_1 :\", best_config_1)\n",
        "print(\"Mejor F1-Score Vect_1 :\", best_score_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvPGlHAPb8sK"
      },
      "source": [
        "### Vect_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC9FnURib8sL",
        "outputId": "9aeef1da-ad37-4dda-d8fb-f528e302a693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_2 : {'min_df': 3, 'ngram_range': (1, 4)}\n",
            "Mejor F1-Score Vect_2 : 0.812457\n"
          ]
        }
      ],
      "source": [
        "best_score_2 = 0\n",
        "best_config_2 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train_processed, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, TfidfVectorizer)\n",
        "    if score > best_score_2:\n",
        "        best_score_2 = score\n",
        "        best_config_2 = config\n",
        "\n",
        "best_configs.append([best_score_2, best_config_2, True, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_2 :\", best_config_2)\n",
        "print(\"Mejor F1-Score Vect_2 :\", best_score_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgipGgrQb8sL"
      },
      "source": [
        "### Vect_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ageb8k8sb8sL",
        "outputId": "c0ff0fbe-ca20-43a8-965d-650ac270b56a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_3 : {'min_df': 3, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_3 : 0.762886\n"
          ]
        }
      ],
      "source": [
        "best_score_3 = 0\n",
        "best_config_3 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, CountVectorizer)\n",
        "    if score > best_score_3:\n",
        "        best_score_3 = score\n",
        "        best_config_3 = config\n",
        "\n",
        "best_configs.append([best_score_3, best_config_3, False, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_3 :\", best_config_3)\n",
        "print(\"Mejor F1-Score Vect_3 :\", best_score_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czqm1FpEb8sL"
      },
      "source": [
        "### Vect_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfP1HKEYb8sL",
        "outputId": "9c2fa19c-b0c7-4ffb-fbe9-9381b754ad81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_4 : {'min_df': 5, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_4 : 0.770027\n"
          ]
        }
      ],
      "source": [
        "best_score_4 = 0\n",
        "best_config_4 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train_processed, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, CountVectorizer)\n",
        "    if score > best_score_4:\n",
        "        best_score_4 = score\n",
        "        best_config_4 = config\n",
        "\n",
        "best_configs.append([best_score_4, best_config_4, True, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_4 :\", best_config_4)\n",
        "print(\"Mejor F1-Score Vect_4 :\", best_score_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA7xLwPEb8sL"
      },
      "source": [
        "### Mejor Vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6FRcH67ab8sL",
        "outputId": "2288aeb1-f43e-4e80-8413-d8f3f94312c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Config</th>\n",
              "      <th>Lemmatization</th>\n",
              "      <th>Type of vectorization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.817644</td>\n",
              "      <td>{'min_df': 1, 'ngram_range': (1, 2)}</td>\n",
              "      <td>False</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.812457</td>\n",
              "      <td>{'min_df': 3, 'ngram_range': (1, 4)}</td>\n",
              "      <td>True</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.762886</td>\n",
              "      <td>{'min_df': 3, 'ngram_range': (1, 2)}</td>\n",
              "      <td>False</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.770027</td>\n",
              "      <td>{'min_df': 5, 'ngram_range': (1, 2)}</td>\n",
              "      <td>True</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Score                                Config  Lemmatization  \\\n",
              "0  0.817644  {'min_df': 1, 'ngram_range': (1, 2)}          False   \n",
              "1  0.812457  {'min_df': 3, 'ngram_range': (1, 4)}           True   \n",
              "2  0.762886  {'min_df': 3, 'ngram_range': (1, 2)}          False   \n",
              "3  0.770027  {'min_df': 5, 'ngram_range': (1, 2)}           True   \n",
              "\n",
              "  Type of vectorization  \n",
              "0                 TFIDF  \n",
              "1                 TFIDF  \n",
              "2                 Count  \n",
              "3                 Count  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_configs_df = pd.DataFrame(data=best_configs, columns=[\"Score\", \"Config\", \"Lematizacion\", \"Tipo de vectorizacion\"])\n",
        "best_configs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHiPxPoNb8sM",
        "outputId": "5a56f3a6-f1fa-4f88-ca2a-424f2737b1d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.817644 {'min_df': 1, 'ngram_range': (1, 2)} False TFIDF\n"
          ]
        }
      ],
      "source": [
        "best_index = best_configs_df['Score'].idxmax()\n",
        "\n",
        "best_score = best_configs_df.loc[best_index, 'Score']\n",
        "best_config = best_configs_df.loc[best_index, 'Config']\n",
        "bool_lemma = best_configs_df.loc[best_index, 'Lematizacion']\n",
        "type_vect = best_configs_df.loc[best_index, 'Tipo de vectorizacion']\n",
        "\n",
        "print(f\"Score: {best_score} - Configuracion: {best_config} - Lematizacion: {bool_lemma} - Tipo: {type_vect}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "0oa_7EX-b8sM"
      },
      "outputs": [],
      "source": [
        "if bool_lemma :\n",
        "    # Si vamos a utilizar la lematizacion\n",
        "    X_train = X_train_processed\n",
        "    X_test = X_test_processed\n",
        "if type_vect == \"TFIDF\":\n",
        "    vect = TfidfVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Count\":\n",
        "    vect = CountVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Hashing\":\n",
        "    vect = HashingVectorizer(stop_words=stop_words_es, **best_config)\n",
        "\n",
        "X_train_vect = vect.fit_transform(X_train)\n",
        "X_test_vect = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jys03R8ScnFs"
      },
      "source": [
        "## Busqueda de los hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "PfX7pAHjb8sM",
        "outputId": "6f6eac9d-b035-48a0-a0bf-2be302559f17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
            "15 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.79397339 0.78814784 0.75760198 0.74332864 0.69164928 0.76555762\n",
            " 0.79943571 0.80450551        nan 0.73645977 0.72073651 0.73309522\n",
            "        nan 0.72824097 0.76424224 0.82306817 0.79434932 0.73250745\n",
            " 0.73515834 0.73801386 0.81017138 0.82384856 0.80794914        nan\n",
            " 0.76640241 0.7905503  0.75093806 0.73427485 0.79131604 0.72779503]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parametros: {'n_estimators': 400, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 6, 'criterion': 'gini'}\n",
            "Mejor F1 Score: 0.8238485580018311\n"
          ]
        }
      ],
      "source": [
        "# Los hiperparametros a probar\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [2, 3, 4, 5, 6],\n",
        "    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
        "    'min_samples_split': [1, 2, 3, 4, 5, 7, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5, 7, 10, 15],\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_distributions, cv=5, n_iter=30, scoring=f1_scorer)\n",
        "random_search.fit(X_train_vect, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "print(f'Mejores parametros: {best_params}')\n",
        "print(f'Mejor F1 Score: {best_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Uyr_M-bcb8sN",
        "outputId": "aa396ef4-6c20-4297-f05f-29836a9305b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.822934573768834\n"
          ]
        }
      ],
      "source": [
        "best_rf_model = random_search.best_estimator_\n",
        "best_rf_model.fit(X_train_vect, y_train)\n",
        "y_pred = best_rf_model.predict(X_test_vect)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "rj-0kuk3b8sN",
        "outputId": "ce2cdde1-26d2-4ed3-8b28-bd34e2f2b5da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/rf_model_2024-06-15.joblib']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exportaciones\n",
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "joblib.dump(random_search, f'Modelos/rf_model_random_search_{current_date}.joblib')\n",
        "joblib.dump(best_rf_model, f'Modelos/rf_model_{current_date}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J2D1MtCcnFs"
      },
      "source": [
        "## Conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UPSw5ZN1SYKz",
        "outputId": "5ac631fa-91af-4a70-fa21-bd3554176067"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    positivo\n",
              "2     60002    positivo\n",
              "3     60003    negativo\n",
              "4     60004    negativo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    positivo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if bool_lemma:\n",
        "    # Si utilizamos el conjunto con lematizacion\n",
        "    conjunto_test = conjunto_test_processed.copy()\n",
        "    X_conjunto_test = vect.transform(conjunto_test)\n",
        "    \n",
        "else :\n",
        "    conjunto_test = conjunto_test.set_index(conjunto_test['ID'])\n",
        "    X_conjunto_test = vect.transform(conjunto_test['review_es'])\n",
        "\n",
        "pred_test = best_rf_model.predict(X_conjunto_test)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWTiatSucnFt"
      },
      "source": [
        "## Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "GNu7DYlJS-Or"
      },
      "outputs": [],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/RandomForest_{current_date}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nvFRYbOKSSm"
      },
      "source": [
        "# 3. XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasets a cargar\n",
        "X_train = pd.read_csv('Datasets/X_train.csv', index_col=0)['review_es']\n",
        "X_test = pd.read_csv('Datasets/X_test.csv', index_col=0)['review_es']\n",
        "y_train = pd.read_csv('Datasets/y_train.csv', index_col=0)['sentimiento']\n",
        "y_test = pd.read_csv('Datasets/y_test.csv', index_col=0)['sentimiento']\n",
        "\n",
        "# Esos son los que fueron lematizados\n",
        "X_train_processed = pd.read_csv('Datasets/X_train_processed.csv', index_col=0)['review_es']\n",
        "X_test_processed = pd.read_csv('Datasets/X_test_processed.csv', index_col=0)['review_es']\n",
        "conjunto_test_processed = pd.read_csv('Datasets/conjunto_test_processed.csv', index_col=0)['review_es']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfkqgq77cnFt"
      },
      "source": [
        "## Vectorizacion de las críticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a hacer diferentes vectorizaciones para elegir la mejor :\n",
        "- Vect_1 : TFIDF Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_2 : TFIDF Vectorizer con lematizacion y con hiperparametros afinados\n",
        "- Vect_3 : Count Vectorizer sin lematizacion y con hiperparametros afinados\n",
        "- Vect_4 : Count Vectorizer con lematizacion y con hiperparametros afinados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_configs = []\n",
        "\n",
        "# Creacion de las diferentes combinaciones de hiperparametros\n",
        "min_dfs = [1, 2, 3, 4, 5, 8, 10, 15]\n",
        "ngram_ranges = [(1, 2), (1, 3), (1, 4)]\n",
        "configs = [{'min_df': min_df, 'ngram_range': ngram_range} for min_df in min_dfs for ngram_range in ngram_ranges]\n",
        "\n",
        "# Model de referencia para encontrar la vectorizacion optimizada\n",
        "xgb_old_model = joblib.load('Modelos/xgb_model_2024-06-15.joblib')\n",
        "\n",
        "def test_config(config, X_train, y_train, vectorizer):\n",
        "    vect = vectorizer(stop_words=stop_words_es, **config)\n",
        "    X_train_vect = vect.fit_transform(X_train)\n",
        "    score = cross_val_score(xgb_old_model, X_train_vect, y_train, cv=10, scoring='f1_macro')\n",
        "    return round(score.mean(), 6)\n",
        "\n",
        "# Funcion para guardar un sample de nuestros datasets\n",
        "def sample_df(X, y):\n",
        "    sample_size = int(0.1 * X.shape[0])\n",
        "    sample_indices = np.random.choice(X.shape[0], size=sample_size, replace=False)\n",
        "    X_sampled = X.iloc[sample_indices]\n",
        "    y_sampled = y.iloc[sample_indices]\n",
        "    return X_sampled, y_sampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vect_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_1 : {'min_df': 1, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_1 : 0.817644\n"
          ]
        }
      ],
      "source": [
        "best_score_1 = 0\n",
        "best_config_1 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, TfidfVectorizer)\n",
        "    if score > best_score_1:\n",
        "        best_score_1 = score\n",
        "        best_config_1 = config\n",
        "\n",
        "best_configs.append([best_score_1, best_config_1, False, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_1 :\", best_config_1)\n",
        "print(\"Mejor F1-Score Vect_1 :\", best_score_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vect_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_2 : {'min_df': 3, 'ngram_range': (1, 4)}\n",
            "Mejor F1-Score Vect_2 : 0.812457\n"
          ]
        }
      ],
      "source": [
        "best_score_2 = 0\n",
        "best_config_2 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train_processed, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, TfidfVectorizer)\n",
        "    if score > best_score_2:\n",
        "        best_score_2 = score\n",
        "        best_config_2 = config\n",
        "\n",
        "best_configs.append([best_score_2, best_config_2, True, \"TFIDF\"])\n",
        "\n",
        "print(\"Mejor config Vect_2 :\", best_config_2)\n",
        "print(\"Mejor F1-Score Vect_2 :\", best_score_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vect_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_3 : {'min_df': 3, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_3 : 0.762886\n"
          ]
        }
      ],
      "source": [
        "best_score_3 = 0\n",
        "best_config_3 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, CountVectorizer)\n",
        "    if score > best_score_3:\n",
        "        best_score_3 = score\n",
        "        best_config_3 = config\n",
        "\n",
        "best_configs.append([best_score_3, best_config_3, False, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_3 :\", best_config_3)\n",
        "print(\"Mejor F1-Score Vect_3 :\", best_score_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vect_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor config Vect_4 : {'min_df': 5, 'ngram_range': (1, 2)}\n",
            "Mejor F1-Score Vect_4 : 0.770027\n"
          ]
        }
      ],
      "source": [
        "best_score_4 = 0\n",
        "best_config_4 = None\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train_processed, y_train)\n",
        "\n",
        "for config in configs:\n",
        "    score = test_config(config, X_train_sampled, y_train_sampled, CountVectorizer)\n",
        "    if score > best_score_4:\n",
        "        best_score_4 = score\n",
        "        best_config_4 = config\n",
        "\n",
        "best_configs.append([best_score_4, best_config_4, True, \"Count\"])\n",
        "\n",
        "print(\"Mejor config Vect_4 :\", best_config_4)\n",
        "print(\"Mejor F1-Score Vect_4 :\", best_score_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mejor Vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Config</th>\n",
              "      <th>Lemmatization</th>\n",
              "      <th>Type of vectorization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.817644</td>\n",
              "      <td>{'min_df': 1, 'ngram_range': (1, 2)}</td>\n",
              "      <td>False</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.812457</td>\n",
              "      <td>{'min_df': 3, 'ngram_range': (1, 4)}</td>\n",
              "      <td>True</td>\n",
              "      <td>TFIDF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.762886</td>\n",
              "      <td>{'min_df': 3, 'ngram_range': (1, 2)}</td>\n",
              "      <td>False</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.770027</td>\n",
              "      <td>{'min_df': 5, 'ngram_range': (1, 2)}</td>\n",
              "      <td>True</td>\n",
              "      <td>Count</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Score                                Config  Lemmatization  \\\n",
              "0  0.817644  {'min_df': 1, 'ngram_range': (1, 2)}          False   \n",
              "1  0.812457  {'min_df': 3, 'ngram_range': (1, 4)}           True   \n",
              "2  0.762886  {'min_df': 3, 'ngram_range': (1, 2)}          False   \n",
              "3  0.770027  {'min_df': 5, 'ngram_range': (1, 2)}           True   \n",
              "\n",
              "  Type of vectorization  \n",
              "0                 TFIDF  \n",
              "1                 TFIDF  \n",
              "2                 Count  \n",
              "3                 Count  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_configs_df = pd.DataFrame(data=best_configs, columns=[\"Score\", \"Config\", \"Lematizacion\", \"Tipo de vectorizacion\"])\n",
        "best_configs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.817644 {'min_df': 1, 'ngram_range': (1, 2)} False TFIDF\n"
          ]
        }
      ],
      "source": [
        "best_index = best_configs_df['Score'].idxmax()\n",
        "\n",
        "best_score = best_configs_df.loc[best_index, 'Score']\n",
        "best_config = best_configs_df.loc[best_index, 'Config']\n",
        "bool_lemma = best_configs_df.loc[best_index, 'Lematizacion']\n",
        "type_vect = best_configs_df.loc[best_index, 'Tipo de vectorizacion']\n",
        "\n",
        "print(f\"Score: {best_score} - Configuracion: {best_config} - Lematizacion: {bool_lemma} - Tipo: {type_vect}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if bool_lemma :\n",
        "    # Si vamos a utilizar la lematizacion\n",
        "    X_train = X_train_processed\n",
        "    X_test = X_test_processed\n",
        "if type_vect == \"TFIDF\":\n",
        "    vect = TfidfVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Count\":\n",
        "    vect = CountVectorizer(stop_words=stop_words_es, **best_config)\n",
        "elif type_vect == \"Hashing\":\n",
        "    vect = HashingVectorizer(stop_words=stop_words_es, **best_config)\n",
        "\n",
        "X_train_vect = vect.fit_transform(X_train)\n",
        "X_test_vect = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klmBJCYpcnFt"
      },
      "source": [
        "## Busqueda de los hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "DGVIGtxjKSSn"
      },
      "outputs": [],
      "source": [
        "# Los hiperparametros a probar\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [2, 3, 4, 5, 6],\n",
        "    'learning_rate': [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.15, 0.2],\n",
        "    'gamma': [0, 0.25, 0.5, 1, 2, 3],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'early_stopping_rounds': [5, 10, 20]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "X_train_sampled, y_train_sampled = sample_df(X_train_vect, y_train)\n",
        "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_distributions, cv=5, n_iter=30, scoring=f1_scorer)\n",
        "random_search.fit(X_train_sampled, y_train_sampled)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "print(f'Mejores parametros: {best_params}')\n",
        "print(f'Mejor F1 Score: {best_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "xRd4fngGcnFu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.66850\n",
            "[1]\tvalidation_0-logloss:0.64941\n",
            "[2]\tvalidation_0-logloss:0.63408\n",
            "[3]\tvalidation_0-logloss:0.62248\n",
            "[4]\tvalidation_0-logloss:0.61195\n",
            "[5]\tvalidation_0-logloss:0.60315\n",
            "[6]\tvalidation_0-logloss:0.59491\n",
            "[7]\tvalidation_0-logloss:0.58795\n",
            "[8]\tvalidation_0-logloss:0.58050\n",
            "[9]\tvalidation_0-logloss:0.57405\n",
            "[10]\tvalidation_0-logloss:0.56877\n",
            "[11]\tvalidation_0-logloss:0.56365\n",
            "[12]\tvalidation_0-logloss:0.55903\n",
            "[13]\tvalidation_0-logloss:0.55369\n",
            "[14]\tvalidation_0-logloss:0.54970\n",
            "[15]\tvalidation_0-logloss:0.54526\n",
            "[16]\tvalidation_0-logloss:0.54161\n",
            "[17]\tvalidation_0-logloss:0.53768\n",
            "[18]\tvalidation_0-logloss:0.53415\n",
            "[19]\tvalidation_0-logloss:0.53087\n",
            "[20]\tvalidation_0-logloss:0.52747\n",
            "[21]\tvalidation_0-logloss:0.52417\n",
            "[22]\tvalidation_0-logloss:0.52152\n",
            "[23]\tvalidation_0-logloss:0.51892\n",
            "[24]\tvalidation_0-logloss:0.51591\n",
            "[25]\tvalidation_0-logloss:0.51338\n",
            "[26]\tvalidation_0-logloss:0.51078\n",
            "[27]\tvalidation_0-logloss:0.50809\n",
            "[28]\tvalidation_0-logloss:0.50572\n",
            "[29]\tvalidation_0-logloss:0.50299\n",
            "[30]\tvalidation_0-logloss:0.49996\n",
            "[31]\tvalidation_0-logloss:0.49762\n",
            "[32]\tvalidation_0-logloss:0.49538\n",
            "[33]\tvalidation_0-logloss:0.49307\n",
            "[34]\tvalidation_0-logloss:0.49146\n",
            "[35]\tvalidation_0-logloss:0.48962\n",
            "[36]\tvalidation_0-logloss:0.48737\n",
            "[37]\tvalidation_0-logloss:0.48512\n",
            "[38]\tvalidation_0-logloss:0.48322\n",
            "[39]\tvalidation_0-logloss:0.48112\n",
            "[40]\tvalidation_0-logloss:0.47964\n",
            "[41]\tvalidation_0-logloss:0.47802\n",
            "[42]\tvalidation_0-logloss:0.47614\n",
            "[43]\tvalidation_0-logloss:0.47464\n",
            "[44]\tvalidation_0-logloss:0.47280\n",
            "[45]\tvalidation_0-logloss:0.47116\n",
            "[46]\tvalidation_0-logloss:0.46958\n",
            "[47]\tvalidation_0-logloss:0.46774\n",
            "[48]\tvalidation_0-logloss:0.46591\n",
            "[49]\tvalidation_0-logloss:0.46431\n",
            "[50]\tvalidation_0-logloss:0.46279\n",
            "[51]\tvalidation_0-logloss:0.46114\n",
            "[52]\tvalidation_0-logloss:0.46000\n",
            "[53]\tvalidation_0-logloss:0.45879\n",
            "[54]\tvalidation_0-logloss:0.45764\n",
            "[55]\tvalidation_0-logloss:0.45636\n",
            "[56]\tvalidation_0-logloss:0.45515\n",
            "[57]\tvalidation_0-logloss:0.45384\n",
            "[58]\tvalidation_0-logloss:0.45282\n",
            "[59]\tvalidation_0-logloss:0.45125\n",
            "[60]\tvalidation_0-logloss:0.44990\n",
            "[61]\tvalidation_0-logloss:0.44884\n",
            "[62]\tvalidation_0-logloss:0.44773\n",
            "[63]\tvalidation_0-logloss:0.44658\n",
            "[64]\tvalidation_0-logloss:0.44533\n",
            "[65]\tvalidation_0-logloss:0.44406\n",
            "[66]\tvalidation_0-logloss:0.44298\n",
            "[67]\tvalidation_0-logloss:0.44213\n",
            "[68]\tvalidation_0-logloss:0.44120\n",
            "[69]\tvalidation_0-logloss:0.44011\n",
            "[70]\tvalidation_0-logloss:0.43918\n",
            "[71]\tvalidation_0-logloss:0.43830\n",
            "[72]\tvalidation_0-logloss:0.43743\n",
            "[73]\tvalidation_0-logloss:0.43645\n",
            "[74]\tvalidation_0-logloss:0.43575\n",
            "[75]\tvalidation_0-logloss:0.43472\n",
            "[76]\tvalidation_0-logloss:0.43387\n",
            "[77]\tvalidation_0-logloss:0.43329\n",
            "[78]\tvalidation_0-logloss:0.43247\n",
            "[79]\tvalidation_0-logloss:0.43193\n",
            "[80]\tvalidation_0-logloss:0.43094\n",
            "[81]\tvalidation_0-logloss:0.42985\n",
            "[82]\tvalidation_0-logloss:0.42872\n",
            "[83]\tvalidation_0-logloss:0.42782\n",
            "[84]\tvalidation_0-logloss:0.42704\n",
            "[85]\tvalidation_0-logloss:0.42613\n",
            "[86]\tvalidation_0-logloss:0.42546\n",
            "[87]\tvalidation_0-logloss:0.42466\n",
            "[88]\tvalidation_0-logloss:0.42391\n",
            "[89]\tvalidation_0-logloss:0.42315\n",
            "[90]\tvalidation_0-logloss:0.42232\n",
            "[91]\tvalidation_0-logloss:0.42143\n",
            "[92]\tvalidation_0-logloss:0.42056\n",
            "[93]\tvalidation_0-logloss:0.41995\n",
            "[94]\tvalidation_0-logloss:0.41928\n",
            "[95]\tvalidation_0-logloss:0.41870\n",
            "[96]\tvalidation_0-logloss:0.41793\n",
            "[97]\tvalidation_0-logloss:0.41708\n",
            "[98]\tvalidation_0-logloss:0.41633\n",
            "[99]\tvalidation_0-logloss:0.41565\n",
            "[100]\tvalidation_0-logloss:0.41511\n",
            "[101]\tvalidation_0-logloss:0.41445\n",
            "[102]\tvalidation_0-logloss:0.41386\n",
            "[103]\tvalidation_0-logloss:0.41323\n",
            "[104]\tvalidation_0-logloss:0.41259\n",
            "[105]\tvalidation_0-logloss:0.41214\n",
            "[106]\tvalidation_0-logloss:0.41147\n",
            "[107]\tvalidation_0-logloss:0.41096\n",
            "[108]\tvalidation_0-logloss:0.41045\n",
            "[109]\tvalidation_0-logloss:0.40965\n",
            "[110]\tvalidation_0-logloss:0.40901\n",
            "[111]\tvalidation_0-logloss:0.40804\n",
            "[112]\tvalidation_0-logloss:0.40779\n",
            "[113]\tvalidation_0-logloss:0.40733\n",
            "[114]\tvalidation_0-logloss:0.40673\n",
            "[115]\tvalidation_0-logloss:0.40621\n",
            "[116]\tvalidation_0-logloss:0.40563\n",
            "[117]\tvalidation_0-logloss:0.40502\n",
            "[118]\tvalidation_0-logloss:0.40441\n",
            "[119]\tvalidation_0-logloss:0.40392\n",
            "[120]\tvalidation_0-logloss:0.40337\n",
            "[121]\tvalidation_0-logloss:0.40285\n",
            "[122]\tvalidation_0-logloss:0.40223\n",
            "[123]\tvalidation_0-logloss:0.40172\n",
            "[124]\tvalidation_0-logloss:0.40108\n",
            "[125]\tvalidation_0-logloss:0.40080\n",
            "[126]\tvalidation_0-logloss:0.40027\n",
            "[127]\tvalidation_0-logloss:0.39981\n",
            "[128]\tvalidation_0-logloss:0.39944\n",
            "[129]\tvalidation_0-logloss:0.39903\n",
            "[130]\tvalidation_0-logloss:0.39845\n",
            "[131]\tvalidation_0-logloss:0.39803\n",
            "[132]\tvalidation_0-logloss:0.39738\n",
            "[133]\tvalidation_0-logloss:0.39716\n",
            "[134]\tvalidation_0-logloss:0.39652\n",
            "[135]\tvalidation_0-logloss:0.39627\n",
            "[136]\tvalidation_0-logloss:0.39575\n",
            "[137]\tvalidation_0-logloss:0.39534\n",
            "[138]\tvalidation_0-logloss:0.39483\n",
            "[139]\tvalidation_0-logloss:0.39445\n",
            "[140]\tvalidation_0-logloss:0.39409\n",
            "[141]\tvalidation_0-logloss:0.39369\n",
            "[142]\tvalidation_0-logloss:0.39325\n",
            "[143]\tvalidation_0-logloss:0.39271\n",
            "[144]\tvalidation_0-logloss:0.39251\n",
            "[145]\tvalidation_0-logloss:0.39191\n",
            "[146]\tvalidation_0-logloss:0.39148\n",
            "[147]\tvalidation_0-logloss:0.39100\n",
            "[148]\tvalidation_0-logloss:0.39073\n",
            "[149]\tvalidation_0-logloss:0.39014\n",
            "[150]\tvalidation_0-logloss:0.38960\n",
            "[151]\tvalidation_0-logloss:0.38907\n",
            "[152]\tvalidation_0-logloss:0.38865\n",
            "[153]\tvalidation_0-logloss:0.38809\n",
            "[154]\tvalidation_0-logloss:0.38777\n",
            "[155]\tvalidation_0-logloss:0.38735\n",
            "[156]\tvalidation_0-logloss:0.38706\n",
            "[157]\tvalidation_0-logloss:0.38664\n",
            "[158]\tvalidation_0-logloss:0.38623\n",
            "[159]\tvalidation_0-logloss:0.38574\n",
            "[160]\tvalidation_0-logloss:0.38543\n",
            "[161]\tvalidation_0-logloss:0.38489\n",
            "[162]\tvalidation_0-logloss:0.38459\n",
            "[163]\tvalidation_0-logloss:0.38433\n",
            "[164]\tvalidation_0-logloss:0.38413\n",
            "[165]\tvalidation_0-logloss:0.38375\n",
            "[166]\tvalidation_0-logloss:0.38333\n",
            "[167]\tvalidation_0-logloss:0.38279\n",
            "[168]\tvalidation_0-logloss:0.38250\n",
            "[169]\tvalidation_0-logloss:0.38220\n",
            "[170]\tvalidation_0-logloss:0.38170\n",
            "[171]\tvalidation_0-logloss:0.38146\n",
            "[172]\tvalidation_0-logloss:0.38111\n",
            "[173]\tvalidation_0-logloss:0.38062\n",
            "[174]\tvalidation_0-logloss:0.38029\n",
            "[175]\tvalidation_0-logloss:0.37983\n",
            "[176]\tvalidation_0-logloss:0.37953\n",
            "[177]\tvalidation_0-logloss:0.37921\n",
            "[178]\tvalidation_0-logloss:0.37890\n",
            "[179]\tvalidation_0-logloss:0.37840\n",
            "[180]\tvalidation_0-logloss:0.37801\n",
            "[181]\tvalidation_0-logloss:0.37768\n",
            "[182]\tvalidation_0-logloss:0.37742\n",
            "[183]\tvalidation_0-logloss:0.37725\n",
            "[184]\tvalidation_0-logloss:0.37685\n",
            "[185]\tvalidation_0-logloss:0.37656\n",
            "[186]\tvalidation_0-logloss:0.37626\n",
            "[187]\tvalidation_0-logloss:0.37605\n",
            "[188]\tvalidation_0-logloss:0.37567\n",
            "[189]\tvalidation_0-logloss:0.37508\n",
            "[190]\tvalidation_0-logloss:0.37464\n",
            "[191]\tvalidation_0-logloss:0.37436\n",
            "[192]\tvalidation_0-logloss:0.37397\n",
            "[193]\tvalidation_0-logloss:0.37369\n",
            "[194]\tvalidation_0-logloss:0.37345\n",
            "[195]\tvalidation_0-logloss:0.37316\n",
            "[196]\tvalidation_0-logloss:0.37279\n",
            "[197]\tvalidation_0-logloss:0.37261\n",
            "[198]\tvalidation_0-logloss:0.37241\n",
            "[199]\tvalidation_0-logloss:0.37230\n",
            "[200]\tvalidation_0-logloss:0.37211\n",
            "[201]\tvalidation_0-logloss:0.37173\n",
            "[202]\tvalidation_0-logloss:0.37135\n",
            "[203]\tvalidation_0-logloss:0.37112\n",
            "[204]\tvalidation_0-logloss:0.37067\n",
            "[205]\tvalidation_0-logloss:0.37036\n",
            "[206]\tvalidation_0-logloss:0.37021\n",
            "[207]\tvalidation_0-logloss:0.36991\n",
            "[208]\tvalidation_0-logloss:0.36959\n",
            "[209]\tvalidation_0-logloss:0.36922\n",
            "[210]\tvalidation_0-logloss:0.36902\n",
            "[211]\tvalidation_0-logloss:0.36883\n",
            "[212]\tvalidation_0-logloss:0.36844\n",
            "[213]\tvalidation_0-logloss:0.36812\n",
            "[214]\tvalidation_0-logloss:0.36779\n",
            "[215]\tvalidation_0-logloss:0.36742\n",
            "[216]\tvalidation_0-logloss:0.36734\n",
            "[217]\tvalidation_0-logloss:0.36717\n",
            "[218]\tvalidation_0-logloss:0.36684\n",
            "[219]\tvalidation_0-logloss:0.36645\n",
            "[220]\tvalidation_0-logloss:0.36622\n",
            "[221]\tvalidation_0-logloss:0.36592\n",
            "[222]\tvalidation_0-logloss:0.36568\n",
            "[223]\tvalidation_0-logloss:0.36545\n",
            "[224]\tvalidation_0-logloss:0.36520\n",
            "[225]\tvalidation_0-logloss:0.36496\n",
            "[226]\tvalidation_0-logloss:0.36468\n",
            "[227]\tvalidation_0-logloss:0.36437\n",
            "[228]\tvalidation_0-logloss:0.36428\n",
            "[229]\tvalidation_0-logloss:0.36397\n",
            "[230]\tvalidation_0-logloss:0.36388\n",
            "[231]\tvalidation_0-logloss:0.36367\n",
            "[232]\tvalidation_0-logloss:0.36354\n",
            "[233]\tvalidation_0-logloss:0.36338\n",
            "[234]\tvalidation_0-logloss:0.36315\n",
            "[235]\tvalidation_0-logloss:0.36294\n",
            "[236]\tvalidation_0-logloss:0.36266\n",
            "[237]\tvalidation_0-logloss:0.36259\n",
            "[238]\tvalidation_0-logloss:0.36226\n",
            "[239]\tvalidation_0-logloss:0.36202\n",
            "[240]\tvalidation_0-logloss:0.36185\n",
            "[241]\tvalidation_0-logloss:0.36157\n",
            "[242]\tvalidation_0-logloss:0.36149\n",
            "[243]\tvalidation_0-logloss:0.36127\n",
            "[244]\tvalidation_0-logloss:0.36094\n",
            "[245]\tvalidation_0-logloss:0.36073\n",
            "[246]\tvalidation_0-logloss:0.36048\n",
            "[247]\tvalidation_0-logloss:0.36016\n",
            "[248]\tvalidation_0-logloss:0.35983\n",
            "[249]\tvalidation_0-logloss:0.35966\n",
            "[250]\tvalidation_0-logloss:0.35956\n",
            "[251]\tvalidation_0-logloss:0.35927\n",
            "[252]\tvalidation_0-logloss:0.35914\n",
            "[253]\tvalidation_0-logloss:0.35892\n",
            "[254]\tvalidation_0-logloss:0.35885\n",
            "[255]\tvalidation_0-logloss:0.35861\n",
            "[256]\tvalidation_0-logloss:0.35831\n",
            "[257]\tvalidation_0-logloss:0.35815\n",
            "[258]\tvalidation_0-logloss:0.35812\n",
            "[259]\tvalidation_0-logloss:0.35812\n",
            "[260]\tvalidation_0-logloss:0.35793\n",
            "[261]\tvalidation_0-logloss:0.35764\n",
            "[262]\tvalidation_0-logloss:0.35748\n",
            "[263]\tvalidation_0-logloss:0.35730\n",
            "[264]\tvalidation_0-logloss:0.35712\n",
            "[265]\tvalidation_0-logloss:0.35691\n",
            "[266]\tvalidation_0-logloss:0.35677\n",
            "[267]\tvalidation_0-logloss:0.35665\n",
            "[268]\tvalidation_0-logloss:0.35647\n",
            "[269]\tvalidation_0-logloss:0.35625\n",
            "[270]\tvalidation_0-logloss:0.35586\n",
            "[271]\tvalidation_0-logloss:0.35583\n",
            "[272]\tvalidation_0-logloss:0.35572\n",
            "[273]\tvalidation_0-logloss:0.35559\n",
            "[274]\tvalidation_0-logloss:0.35539\n",
            "[275]\tvalidation_0-logloss:0.35522\n",
            "[276]\tvalidation_0-logloss:0.35497\n",
            "[277]\tvalidation_0-logloss:0.35483\n",
            "[278]\tvalidation_0-logloss:0.35469\n",
            "[279]\tvalidation_0-logloss:0.35455\n",
            "[280]\tvalidation_0-logloss:0.35439\n",
            "[281]\tvalidation_0-logloss:0.35430\n",
            "[282]\tvalidation_0-logloss:0.35409\n",
            "[283]\tvalidation_0-logloss:0.35393\n",
            "[284]\tvalidation_0-logloss:0.35392\n",
            "[285]\tvalidation_0-logloss:0.35368\n",
            "[286]\tvalidation_0-logloss:0.35350\n",
            "[287]\tvalidation_0-logloss:0.35324\n",
            "[288]\tvalidation_0-logloss:0.35306\n",
            "[289]\tvalidation_0-logloss:0.35283\n",
            "[290]\tvalidation_0-logloss:0.35265\n",
            "[291]\tvalidation_0-logloss:0.35247\n",
            "[292]\tvalidation_0-logloss:0.35219\n",
            "[293]\tvalidation_0-logloss:0.35204\n",
            "[294]\tvalidation_0-logloss:0.35188\n",
            "[295]\tvalidation_0-logloss:0.35172\n",
            "[296]\tvalidation_0-logloss:0.35154\n",
            "[297]\tvalidation_0-logloss:0.35143\n",
            "[298]\tvalidation_0-logloss:0.35128\n",
            "[299]\tvalidation_0-logloss:0.35117\n",
            "F1 Score: 0.8546545384168763\n"
          ]
        }
      ],
      "source": [
        "best_xgb_model = random_search.best_estimator_\n",
        "best_xgb_model.fit(X_train_vect, y_train, early_stopping_rounds=10, eval_set=[(X_test_vect, y_test)])\n",
        "y_pred = best_xgb_model.predict(X_test_vect)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "EgDatTHwcnFu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/xgb_model_2024-06-15.joblib']"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exportaciones\n",
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "joblib.dump(random_search, f'Modelos/xgb_model_random_search_{current_date}.joblib')\n",
        "joblib.dump(best_xgb_model, f'Modelos/xgb_model_{current_date}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CiyUw5BcnFu"
      },
      "source": [
        "## Conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "T7zaobVqKSSn"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    positivo\n",
              "2     60002    negativo\n",
              "3     60003    negativo\n",
              "4     60004    negativo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    positivo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if bool_lemma:\n",
        "    # Si utilizamos el conjunto con lematizacion\n",
        "    conjunto_test = conjunto_test_processed.copy()\n",
        "    X_conjunto_test = vect.transform(conjunto_test)\n",
        "    \n",
        "else :\n",
        "    conjunto_test = conjunto_test.set_index(conjunto_test['ID'])\n",
        "    X_conjunto_test = vect.transform(conjunto_test['review_es'])\n",
        "\n",
        "pred_test = best_xgb_model.predict(X_conjunto_test)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF5pKkAdcnFu"
      },
      "source": [
        "## Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "szOMmNTBKSSo"
      },
      "outputs": [],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/XGBoost_{current_date}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KUgCMFaKSSo"
      },
      "source": [
        "# 4. Red Neuronal aplicando Keras y Tensor Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGhJmT5Hb8sQ"
      },
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "myEWhrntb8sQ"
      },
      "outputs": [],
      "source": [
        "# Datasets a cargar\n",
        "X_train = pd.read_csv('Datasets/X_train.csv', index_col=0)['review_es']\n",
        "X_test = pd.read_csv('Datasets/X_test.csv', index_col=0)['review_es']\n",
        "y_train = pd.read_csv('Datasets/y_train.csv', index_col=0)['sentimiento']\n",
        "y_test = pd.read_csv('Datasets/y_test.csv', index_col=0)['sentimiento']\n",
        "\n",
        "# Esos son los que fueron lematizados\n",
        "X_train_processed = pd.read_csv('Datasets/X_train_processed.csv', index_col=0)['review_es']\n",
        "X_test_processed = pd.read_csv('Datasets/X_test_processed.csv', index_col=0)['review_es']\n",
        "conjunto_test_processed = pd.read_csv('Datasets/conjunto_test_processed.csv', index_col=0)['review_es']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Si queremos aumentar los datos\n",
        "\n",
        "Eso fue una tentativa no exitosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion para eliminar algunas palabras en cada crítica y anadirlas en el conjunto inicial\n",
        "def random_deletion(text, p):\n",
        "    words = text.split()\n",
        "    if len(words) == 1:\n",
        "        return words\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        r = random.uniform(0, 1)\n",
        "        if r > p:\n",
        "            new_words.append(word)\n",
        "    if len(new_words) == 0:\n",
        "        print([random.choice(words)])\n",
        "        return [random.choice(words)]\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "X_train_augmented_random_deletion = X_train_processed.apply(lambda x: random_deletion(x, 0.3))\n",
        "X_train_augmented_random_deletion.index = X_train_augmented_random_deletion.index + 40000\n",
        "y_train_augmented_random_deletion = y_train.copy()\n",
        "y_train_augmented_random_deletion.index = y_train_augmented_random_deletion.index + 40000\n",
        "\n",
        "X_train_augmented = pd.concat([X_train_processed, X_train_augmented_random_deletion])\n",
        "y_train_augmented = pd.concat([y_train, y_train_augmented_random_deletion])\n",
        "X_train = X_train_augmented\n",
        "y_train = y_train_augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqQz2wWjb8sQ"
      },
      "source": [
        "## Eleccion del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wRT4R1iCKSSo",
        "outputId": "620c4209-b4b8-40b2-ede1-a37c19feaf32"
      },
      "outputs": [],
      "source": [
        "# Transformacion en lista\n",
        "X_train_list = X_train_processed.tolist()\n",
        "X_test_list = X_test_processed.tolist()\n",
        "\n",
        "# Transformacion en array\n",
        "X_train_array = np.array(X_train_list, dtype=object).reshape(-1,1)\n",
        "X_test_array = np.array(X_test_list, dtype=object).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lRYYLHfLb8sQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 128, 'learning_rate': 0.0005, 'threshold': 0.45, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - f1_score: 0.7818 - loss: 1.6088 - val_f1_score: 0.8642 - val_loss: 0.5475 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - f1_score: 0.8822 - loss: 0.4781 - val_f1_score: 0.8697 - val_loss: 0.4458 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - f1_score: 0.8809 - loss: 0.4216 - val_f1_score: 0.8748 - val_loss: 0.4304 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.8847 - loss: 0.4120 - val_f1_score: 0.8677 - val_loss: 0.4278 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - f1_score: 0.8818 - loss: 0.4028 - val_f1_score: 0.8728 - val_loss: 0.4191 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - f1_score: 0.8827 - loss: 0.3989 - val_f1_score: 0.8688 - val_loss: 0.4183 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.8826 - loss: 0.3976 - val_f1_score: 0.8713 - val_loss: 0.4147 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - f1_score: 0.8856 - loss: 0.3930 - val_f1_score: 0.8558 - val_loss: 0.4666 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - f1_score: 0.8857 - loss: 0.3869 - val_f1_score: 0.8657 - val_loss: 0.4302 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - f1_score: 0.8864 - loss: 0.3871 - val_f1_score: 0.8681 - val_loss: 0.4161 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - f1_score: 0.9034 - loss: 0.3505 - val_f1_score: 0.8760 - val_loss: 0.3849 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - f1_score: 0.9093 - loss: 0.3281 - val_f1_score: 0.8797 - val_loss: 0.3764 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.9112 - loss: 0.3215 - val_f1_score: 0.8806 - val_loss: 0.3769 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.9117 - loss: 0.3154 - val_f1_score: 0.8805 - val_loss: 0.3733 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - f1_score: 0.9118 - loss: 0.3170 - val_f1_score: 0.8809 - val_loss: 0.3733 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.9114 - loss: 0.3149 - val_f1_score: 0.8813 - val_loss: 0.3720 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - f1_score: 0.9152 - loss: 0.3111 - val_f1_score: 0.8795 - val_loss: 0.3737 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.9110 - loss: 0.3151 - val_f1_score: 0.8824 - val_loss: 0.3734 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.9174 - loss: 0.3073 - val_f1_score: 0.8812 - val_loss: 0.3749 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - f1_score: 0.9184 - loss: 0.3023 - val_f1_score: 0.8814 - val_loss: 0.3718 - learning_rate: 2.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9217 - loss: 0.2972 - val_f1_score: 0.8813 - val_loss: 0.3714 - learning_rate: 2.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9231 - loss: 0.2942 - val_f1_score: 0.8818 - val_loss: 0.3713 - learning_rate: 2.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9225 - loss: 0.2964 - val_f1_score: 0.8812 - val_loss: 0.3713 - learning_rate: 2.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - f1_score: 0.9223 - loss: 0.2959 - val_f1_score: 0.8813 - val_loss: 0.3711 - learning_rate: 2.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9201 - loss: 0.2982 - val_f1_score: 0.8813 - val_loss: 0.3711 - learning_rate: 2.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9199 - loss: 0.2967 - val_f1_score: 0.8812 - val_loss: 0.3712 - learning_rate: 2.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9232 - loss: 0.2923 - val_f1_score: 0.8809 - val_loss: 0.3712 - learning_rate: 2.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9227 - loss: 0.2956 - val_f1_score: 0.8813 - val_loss: 0.3714 - learning_rate: 4.0000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9236 - loss: 0.2937 - val_f1_score: 0.8813 - val_loss: 0.3712 - learning_rate: 4.0000e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - f1_score: 0.9256 - loss: 0.2932 - val_f1_score: 0.8811 - val_loss: 0.3711 - learning_rate: 4.0000e-06\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "F1-Score : 0.8805785517175755\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 32, 'learning_rate': 0.005, 'threshold': 0.4, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - f1_score: 0.8014 - loss: 0.7485 - val_f1_score: 0.8488 - val_loss: 0.5770 - learning_rate: 0.0050\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - f1_score: 0.8445 - loss: 0.5409 - val_f1_score: 0.8545 - val_loss: 0.5020 - learning_rate: 0.0050\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - f1_score: 0.8474 - loss: 0.5214 - val_f1_score: 0.8523 - val_loss: 0.5049 - learning_rate: 0.0050\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - f1_score: 0.8427 - loss: 0.5266 - val_f1_score: 0.8477 - val_loss: 0.5217 - learning_rate: 0.0050\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - f1_score: 0.8478 - loss: 0.5116 - val_f1_score: 0.8334 - val_loss: 0.5488 - learning_rate: 0.0050\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "F1-Score : 0.8487832591610643\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 32, 'learning_rate': 0.0001, 'threshold': 0.4, 'max_tokens': 20000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - f1_score: 0.7291 - loss: 1.0042 - val_f1_score: 0.8771 - val_loss: 0.5548 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - f1_score: 0.9012 - loss: 0.4847 - val_f1_score: 0.8818 - val_loss: 0.4627 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - f1_score: 0.9186 - loss: 0.3838 - val_f1_score: 0.8905 - val_loss: 0.4191 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - f1_score: 0.9328 - loss: 0.3321 - val_f1_score: 0.8892 - val_loss: 0.4027 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - f1_score: 0.9354 - loss: 0.3066 - val_f1_score: 0.8915 - val_loss: 0.3918 - learning_rate: 1.0000e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "F1-Score : 0.8770902220122814\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 256, 'learning_rate': 0.01, 'threshold': 0.42, 'max_tokens': 10000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - f1_score: 0.7802 - loss: 2.1534 - val_f1_score: 0.8204 - val_loss: 0.7564 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - f1_score: 0.8343 - loss: 0.6942 - val_f1_score: 0.8419 - val_loss: 0.6817 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - f1_score: 0.8339 - loss: 0.6883 - val_f1_score: 0.8344 - val_loss: 0.6717 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - f1_score: 0.8351 - loss: 0.6743 - val_f1_score: 0.8427 - val_loss: 0.6592 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - f1_score: 0.8367 - loss: 0.7239 - val_f1_score: 0.8401 - val_loss: 0.6550 - learning_rate: 0.0100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "F1-Score : 0.8247035573122531\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 128, 'learning_rate': 0.01, 'threshold': 0.45, 'max_tokens': 20000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - f1_score: 0.7697 - loss: 1.7205 - val_f1_score: 0.8353 - val_loss: 0.7591 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - f1_score: 0.8285 - loss: 0.7859 - val_f1_score: 0.8366 - val_loss: 0.7849 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - f1_score: 0.8332 - loss: 0.7715 - val_f1_score: 0.8348 - val_loss: 0.7376 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - f1_score: 0.8282 - loss: 0.7567 - val_f1_score: 0.8354 - val_loss: 0.8428 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - f1_score: 0.8299 - loss: 0.8952 - val_f1_score: 0.8306 - val_loss: 0.7932 - learning_rate: 0.0100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "F1-Score : 0.8297575440432584\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 256, 'learning_rate': 0.0005, 'threshold': 0.45, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - f1_score: 0.8079 - loss: 2.3070 - val_f1_score: 0.8658 - val_loss: 0.5614 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.8737 - loss: 0.5078 - val_f1_score: 0.8606 - val_loss: 0.5036 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - f1_score: 0.8742 - loss: 0.4530 - val_f1_score: 0.8676 - val_loss: 0.4554 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.8766 - loss: 0.4332 - val_f1_score: 0.8625 - val_loss: 0.4566 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - f1_score: 0.8775 - loss: 0.4275 - val_f1_score: 0.8646 - val_loss: 0.4362 - learning_rate: 5.0000e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "F1-Score : 0.8631739089093848\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 32, 'learning_rate': 0.0001, 'threshold': 0.45, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - f1_score: 0.6801 - loss: 1.2196 - val_f1_score: 0.8436 - val_loss: 0.7553 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - f1_score: 0.8646 - loss: 0.6854 - val_f1_score: 0.8674 - val_loss: 0.5954 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.8892 - loss: 0.5415 - val_f1_score: 0.8786 - val_loss: 0.5177 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9016 - loss: 0.4667 - val_f1_score: 0.8797 - val_loss: 0.4742 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9048 - loss: 0.4190 - val_f1_score: 0.8780 - val_loss: 0.4456 - learning_rate: 1.0000e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "F1-Score : 0.8440571110699054\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 32, 'learning_rate': 0.005, 'threshold': 0.45, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - f1_score: 0.7908 - loss: 0.7199 - val_f1_score: 0.8468 - val_loss: 0.5223 - learning_rate: 0.0050\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.8480 - loss: 0.5368 - val_f1_score: 0.8525 - val_loss: 0.4982 - learning_rate: 0.0050\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - f1_score: 0.8504 - loss: 0.4997 - val_f1_score: 0.8466 - val_loss: 0.5021 - learning_rate: 0.0050\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.8495 - loss: 0.4982 - val_f1_score: 0.8461 - val_loss: 0.5151 - learning_rate: 0.0050\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - f1_score: 0.8492 - loss: 0.4982 - val_f1_score: 0.8566 - val_loss: 0.4923 - learning_rate: 0.0050\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "F1-Score : 0.842230783342506\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 256, 'learning_rate': 0.0001, 'threshold': 0.5, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - f1_score: 0.7080 - loss: 4.2465 - val_f1_score: 0.8714 - val_loss: 1.7920 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.8897 - loss: 1.4965 - val_f1_score: 0.8759 - val_loss: 1.0008 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.8994 - loss: 0.8640 - val_f1_score: 0.8795 - val_loss: 0.6969 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.9035 - loss: 0.6098 - val_f1_score: 0.8767 - val_loss: 0.5603 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - f1_score: 0.9023 - loss: 0.4913 - val_f1_score: 0.8741 - val_loss: 0.4877 - learning_rate: 1.0000e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "F1-Score : 0.8628981036203611\n",
            "Testing parameters: {'optimizer': 'adam', 'dense_length': 512, 'learning_rate': 0.005, 'threshold': 0.4, 'max_tokens': 5000}\n",
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 70ms/step - f1_score: 0.7675 - loss: 2.3452 - val_f1_score: 0.8359 - val_loss: 0.5993 - learning_rate: 0.0050\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - f1_score: 0.8303 - loss: 0.6436 - val_f1_score: 0.8422 - val_loss: 0.5772 - learning_rate: 0.0050\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - f1_score: 0.8332 - loss: 0.5919 - val_f1_score: 0.8370 - val_loss: 0.5818 - learning_rate: 0.0050\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - f1_score: 0.8412 - loss: 0.5505 - val_f1_score: 0.8407 - val_loss: 0.5322 - learning_rate: 0.0050\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - f1_score: 0.8461 - loss: 0.5442 - val_f1_score: 0.8417 - val_loss: 0.5645 - learning_rate: 0.0050\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "F1-Score : 0.8358505923849145\n",
            "Best F1-Score: 0.880579 using {'optimizer': 'adam', 'dense_length': 128, 'learning_rate': 0.0005, 'threshold': 0.45, 'max_tokens': 5000}\n"
          ]
        }
      ],
      "source": [
        "# Funcion para generar un modelo de red neuronal con hiperparametros selecionados\n",
        "def create_model(optimizer='adam', dense_length=64, learning_rate=0.001, rho=0.95, epsilon=1e-07, momentum=0.0, threshold=0.5, max_tokens=10000, dropout_rate=0.5):\n",
        "    \n",
        "    # El optimizador selecionado\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=learning_rate, rho=rho, epsilon=epsilon, momentum=momentum)\n",
        "    elif optimizer == 'adadelta':\n",
        "        opt = Adadelta(learning_rate=learning_rate, rho=rho, epsilon=epsilon)\n",
        "\n",
        "    # Vectorizacion de los textos para utilizarlos\n",
        "    vectorizer = TextVectorization(output_mode='tf-idf', max_tokens=max_tokens)\n",
        "    vectorizer.adapt(X_train_list)\n",
        "\n",
        "    # Nuestro modelo\n",
        "    model = Sequential([\n",
        "        Input(shape=(1,), dtype=tf.string),\n",
        "        vectorizer,\n",
        "        BatchNormalization(),\n",
        "        Dense(dense_length, activation='relu', kernel_regularizer='l2'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_length // 2, activation='relu', kernel_regularizer='l2'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(1, activation='sigmoid', kernel_regularizer='l2')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[F1Score(threshold=threshold)])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Los hiperparametros a probar por tipo de optimizador\n",
        "param_dist_adam = {\n",
        "    'optimizer': ['adam'],\n",
        "    'dense_length': [16, 32, 64, 128, 256, 512],\n",
        "    'learning_rate': [0.1, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
        "    'threshold': [0.4, 0.42, 0.45, 0.5],\n",
        "    'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "    'max_tokens': [5000, 10000, 20000]\n",
        "}\n",
        "param_dist_rmsprop = {\n",
        "    'optimizer': ['rmsprop'],\n",
        "    'dense_length': [16, 32, 64, 128, 256, 512],\n",
        "    'learning_rate': [0.1, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
        "    'rho': [0.85, 0.9, 0.95],\n",
        "    'epsilon': [1e-08, 1e-07, 1e-06],\n",
        "    'momentum': [0.0, 0.2, 0.5],\n",
        "    'threshold': [0.4, 0.42, 0.45, 0.5],\n",
        "    'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "    'max_tokens': [5000, 10000, 20000]\n",
        "}\n",
        "param_dist_adadelta = {\n",
        "    'optimizer': ['adadelta'],\n",
        "    'dense_length': [16, 32, 64, 128, 256, 512],\n",
        "    'learning_rate': [0.1, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
        "    'rho': [0.85, 0.9, 0.95],\n",
        "    'epsilon': [1e-08, 1e-07, 1e-06],\n",
        "    'threshold': [0.4, 0.42, 0.45, 0.5],\n",
        "    'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "    'max_tokens': [5000, 10000, 20000]\n",
        "}\n",
        "param_grid = [\n",
        "    param_dist_adam,\n",
        "    #param_dist_rmsprop,\n",
        "    #param_dist_adadelta\n",
        "]\n",
        "\n",
        "# Funcion disenada para crear un GridSearch adaptado a las redes neuronales\n",
        "def grid_search(X_train, y_train, X_val, y_val, param_grid, n_iter):\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "    \n",
        "    for param_dist in param_grid:\n",
        "        for _ in range(n_iter):\n",
        "            # Para generar solo algunas combinaciones por optimizador\n",
        "            params = {key: random.choice(value) for key, value in param_dist.items()}\n",
        "            print(f\"Testing parameters: {params}\")\n",
        "\n",
        "            model = create_model(**params)\n",
        "\n",
        "            # Esos metodos de regularizacion nos permiten mejorar el modelo\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
        "            callbacks_list = [early_stopping, reduce_lr]\n",
        "            \n",
        "            model.fit(\n",
        "                X_train, y_train, \n",
        "                epochs=20, \n",
        "                batch_size=128, \n",
        "                validation_data=(X_val, y_val), \n",
        "                callbacks=callbacks_list\n",
        "            )\n",
        "            \n",
        "            val_predictions = model.predict(X_val)\n",
        "            val_predictions_cat = np.where(val_predictions>0.4,1,0)\n",
        "            val_predictions_series = pd.Series(val_predictions_cat.flatten(), index=y_val.index)\n",
        "\n",
        "            val_f1 = f1_score(y_val, val_predictions_series)\n",
        "            print(f\"F1-Score : {val_f1}\")\n",
        "            \n",
        "            if val_f1 > best_score:\n",
        "                best_score = val_f1\n",
        "                best_params = params\n",
        "        \n",
        "            model = None\n",
        "            \n",
        "    return best_score, best_params\n",
        "\n",
        "best_score, best_params = grid_search(X_train_array, y_train, X_test_array, y_test, param_grid, n_iter=30)\n",
        "\n",
        "print(\"Best F1-Score: %f using %s\" % (best_score, best_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcIqSze5b8sR"
      },
      "source": [
        "## Fit con el mejor modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JtbqxuUCb8sR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_24           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_24           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m640,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,257</span> (2.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640,257\u001b[0m (2.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,257</span> (2.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m640,257\u001b[0m (2.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - f1_score: 0.7820 - loss: 1.5541 - val_f1_score: 0.8694 - val_loss: 0.5428 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - f1_score: 0.8853 - loss: 0.4721 - val_f1_score: 0.8641 - val_loss: 0.4635 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - f1_score: 0.8822 - loss: 0.4182 - val_f1_score: 0.8646 - val_loss: 0.4392 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - f1_score: 0.8827 - loss: 0.4053 - val_f1_score: 0.8682 - val_loss: 0.4349 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - f1_score: 0.8811 - loss: 0.4092 - val_f1_score: 0.8731 - val_loss: 0.4210 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - f1_score: 0.8827 - loss: 0.3998 - val_f1_score: 0.8741 - val_loss: 0.4241 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.8827 - loss: 0.4004 - val_f1_score: 0.8685 - val_loss: 0.4227 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - f1_score: 0.8808 - loss: 0.3972 - val_f1_score: 0.8675 - val_loss: 0.4386 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.8980 - loss: 0.3580 - val_f1_score: 0.8797 - val_loss: 0.3873 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - f1_score: 0.9074 - loss: 0.3305 - val_f1_score: 0.8789 - val_loss: 0.3802 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9098 - loss: 0.3254 - val_f1_score: 0.8805 - val_loss: 0.3753 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9091 - loss: 0.3226 - val_f1_score: 0.8810 - val_loss: 0.3738 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9092 - loss: 0.3225 - val_f1_score: 0.8783 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9125 - loss: 0.3163 - val_f1_score: 0.8805 - val_loss: 0.3731 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9140 - loss: 0.3110 - val_f1_score: 0.8808 - val_loss: 0.3720 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - f1_score: 0.9128 - loss: 0.3142 - val_f1_score: 0.8807 - val_loss: 0.3722 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9138 - loss: 0.3117 - val_f1_score: 0.8803 - val_loss: 0.3727 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9138 - loss: 0.3118 - val_f1_score: 0.8807 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9185 - loss: 0.3029 - val_f1_score: 0.8809 - val_loss: 0.3730 - learning_rate: 2.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - f1_score: 0.9189 - loss: 0.3009 - val_f1_score: 0.8814 - val_loss: 0.3725 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2b2a05d44c0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vectorizacion de los textos\n",
        "vectorizer = TextVectorization(output_mode='tf-idf', max_tokens=best_params['max_tokens'])\n",
        "vectorizer.adapt(X_train_list)\n",
        "\n",
        "# Nuestro modelo optimizado\n",
        "model = Sequential([\n",
        "    Input(shape=(1,), dtype=tf.string),\n",
        "    vectorizer,\n",
        "    BatchNormalization(),\n",
        "    Dense(best_params['dense_length'], activation='relu', kernel_regularizer='l2'),\n",
        "    Dropout(best_params['dropout_rate']),\n",
        "    Dense(best_params['dense_length'] // 2, activation='relu', kernel_regularizer='l2'),\n",
        "    Dropout(best_params['dropout_rate']),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer='l2')\n",
        "])\n",
        "\n",
        "# Segun el optimizador, compilamos el modelo\n",
        "if best_params['optimizer'] == 'rmsprop':\n",
        "    model.compile(\n",
        "        optimizer=RMSprop(learning_rate=best_params['learning_rate'], rho=best_params['rho'], epsilon=best_params['epsilon'], momentum=best_params['momentum']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[F1Score(threshold=best_params['threshold'])]\n",
        "    )\n",
        "elif best_params['optimizer'] == 'adadelta':\n",
        "    model.compile(\n",
        "        optimizer=Adadelta(learning_rate=best_params['learning_rate'], rho=best_params['rho'], epsilon=best_params['epsilon']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[F1Score(threshold=best_params['threshold'])]\n",
        "    )\n",
        "elif best_params['optimizer'] == 'adam':\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[F1Score(threshold=best_params['threshold'])]\n",
        "    )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Esos metodos de regularizacion nos permiten mejorar el modelo\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
        "callbacks_list = [early_stopping, reduce_lr]\n",
        "\n",
        "model.fit(X_train_array, y_train, epochs=50, batch_size=128, validation_data=(X_test_array, y_test), callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C2QT7dE_b8sR",
        "outputId": "8b85b633-a2b1-497f-d894-afec8a027db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "F1-Score del modelo de red neuronal: 0.8804224820822332\n",
            "Accuracy del modelo de red neuronal: 0.8732\n",
            "Precision del modelo de red neuronal: 0.8388140161725067\n",
            "Recall del modelo de red neuronal: 0.9263742806112324\n"
          ]
        }
      ],
      "source": [
        "y_predic = model.predict(X_test_array)\n",
        "y_predic_cat = np.where(y_predic>y_predic.flatten().mean(),1,0)\n",
        "\n",
        "y_pred_series = pd.Series(y_predic_cat.flatten(), index=y_test.index)\n",
        "\n",
        "f1_score_modelo = f1_score(y_test, y_pred_series)\n",
        "accuracy_score_modelo = accuracy_score(y_test, y_pred_series)\n",
        "precision_score_modelo = precision_score(y_test, y_pred_series)\n",
        "recall_score_modelo = recall_score(y_test, y_pred_series)\n",
        "print(f\"F1-Score del modelo de red neuronal: {f1_score_modelo}\")\n",
        "print(f\"Accuracy del modelo de red neuronal: {accuracy_score_modelo}\")\n",
        "print(f\"Precision del modelo de red neuronal: {precision_score_modelo}\")\n",
        "print(f\"Recall del modelo de red neuronal: {recall_score_modelo}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cy9xJ-Bbb8sR",
        "outputId": "ea6c99df-a28d-47aa-a240-a45fdce25dc9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds_validacion=pd.DataFrame(y_predic_cat,y_test).reset_index()\n",
        "ds_validacion.columns=['y_pred','y_real']\n",
        "\n",
        "tabla=pd.crosstab(ds_validacion.y_pred, ds_validacion.y_real)\n",
        "grf=sns.heatmap(tabla,annot=True, cmap = 'Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJlgPoOJb8sR"
      },
      "source": [
        "## Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u0WYowypb8sR",
        "outputId": "231f1663-0855-4eb8-9eb0-e52cab07ddad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    negativo\n",
              "2     60002    positivo\n",
              "3     60003    positivo\n",
              "4     60004    positivo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    negativo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_conjunto_test = conjunto_test_processed.copy()\n",
        "X_conjunto_test_array = np.array(X_conjunto_test, dtype=object).reshape(-1,1)\n",
        "\n",
        "y_predic = model.predict(X_conjunto_test_array)\n",
        "y_predic_cat = np.where(y_predic>y_predic.flatten().mean(),1,0)\n",
        "\n",
        "y_pred_series = pd.Series(y_predic_cat.flatten(), index=conjunto_test.index)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in y_pred_series]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index + 60000,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2f2Bcz3b8sR"
      },
      "source": [
        "## Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UJ3Xt0bVb8sS",
        "outputId": "30969a1d-8070-4822-eb7b-1882e91977a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "model.save(f'Modelos/red_neuronal_lematizacion_{current_date}.h5')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Red_Neuronal_lematizacion_{current_date}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dpwjSLzKSSo"
      },
      "source": [
        "# 5. Ensamble de 3 modelos (o mas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasets a cargar\n",
        "X_train = pd.read_csv('Datasets/X_train.csv', index_col=0)['review_es']\n",
        "X_test = pd.read_csv('Datasets/X_test.csv', index_col=0)['review_es']\n",
        "y_train = pd.read_csv('Datasets/y_train.csv', index_col=0)['sentimiento']\n",
        "y_test = pd.read_csv('Datasets/y_test.csv', index_col=0)['sentimiento']\n",
        "\n",
        "# Esos son los que fueron lematizados\n",
        "X_train_processed = pd.read_csv('Datasets/X_train_processed.csv', index_col=0)['review_es']\n",
        "X_test_processed = pd.read_csv('Datasets/X_test_processed.csv', index_col=0)['review_es']\n",
        "conjunto_test_processed = pd.read_csv('Datasets/conjunto_test_processed.csv', index_col=0)['review_es']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRK3qUSiGydE"
      },
      "source": [
        "### Creacion del Ensamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tomando los ultimos y los mejores (que no es el ultimo) de cada modelo\n",
        "\n",
        "ultimo_nb_model = joblib.load('Modelos/bn_model_2024-06-15.joblib')\n",
        "mejor_nb_model = joblib.load('Modelos/bn_model_2024-05-31.joblib')\n",
        "\n",
        "# Aca tenemos problemas con ese parametro cuando cargamos el modelo, asi ponemos True cada vez\n",
        "if hasattr(ultimo_nb_model, 'force_alpha') and ultimo_nb_model.force_alpha not in [True, False]:\n",
        "    ultimo_nb_model.force_alpha = True\n",
        "if hasattr(mejor_nb_model, 'force_alpha') and mejor_nb_model.force_alpha not in [True, False]:\n",
        "    mejor_nb_model.force_alpha = True\n",
        "\n",
        "ultimo_xgb_model = joblib.load('Modelos/xgb_model_2024-06-15.joblib')\n",
        "mejor_xgb_model = joblib.load('Modelos/xgb_model_2024-05-28.joblib')\n",
        "\n",
        "ultimo_rf_model = joblib.load('Modelos/rf_model_2024-06-15.joblib')\n",
        "mejor_rf_model = joblib.load('Modelos/rf_model_2024-06-15.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "zUMwWzcIKSSo",
        "outputId": "e1ab4d24-dc3f-4a53-9150-962086b1ee16"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     16\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multimo nb\u001b[39m\u001b[38;5;124m'\u001b[39m, ultimo_nb_model),\n\u001b[0;32m     18\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmejor nb\u001b[39m\u001b[38;5;124m'\u001b[39m, mejor_nb_model),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#('mejor keras', mejor_keras_model)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m ], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39minitial_weights)  \u001b[38;5;66;03m# 'soft' para probabilidades, 'hard' para mayorías\u001b[39;00m\n\u001b[0;32m     27\u001b[0m vect \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39mstop_words_es)\n\u001b[1;32m---> 28\u001b[0m X_train_vect \u001b[38;5;241m=\u001b[39m \u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m X_test_vect \u001b[38;5;241m=\u001b[39m vect\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Ajustar el modelo de ensamble\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2093\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2088\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2089\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2090\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2091\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2092\u001b[0m )\n\u001b[1;32m-> 2093\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1374\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m             )\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1377\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1261\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1260\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1263\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:105\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
            "File \u001b[1;32mc:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:212\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Provides common code for text vectorizers (tokenization logic).\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m _white_spaces \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc):\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode the input into a string of unicode symbols.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    The decoding strategy depends on the vectorizer parameters.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m        A string of unicode symbols.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Utilizamos los F1-Score de Kaggle para ponderar los modelos\n",
        "f1_scores = {\n",
        "    'ultimo nb': 0.74588,\n",
        "    'mejor nb': 0.74840,\n",
        "    'ultimo xgb': 0.70304,\n",
        "    'mejor xgb': 0.71215,\n",
        "    'ultimo rf': 0.68773,\n",
        "    'mejor rf': 0.68773,\n",
        "}\n",
        "\n",
        "# Normalizacion de los pesos\n",
        "total_f1 = sum(f1_scores.values())\n",
        "initial_weights = [score / total_f1 for score in f1_scores.values()]\n",
        "\n",
        "# Creacion del ensamble\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "    ('ultimo nb', ultimo_nb_model),\n",
        "    ('mejor nb', mejor_nb_model),\n",
        "    ('ultimo xgb', ultimo_xgb_model),\n",
        "    ('mejor xgb', mejor_xgb_model),\n",
        "    ('ultimo rf', ultimo_rf_model),\n",
        "    ('mejor rf', mejor_rf_model),\n",
        "], voting='soft', weights=initial_weights)  # 'soft' para probabilidades, 'hard' para mayorías\n",
        "\n",
        "# Vectorizacion de los conjuntos\n",
        "vect = TfidfVectorizer(stop_words=stop_words_es)\n",
        "X_train_vect = vect.fit_transform(X_train)\n",
        "X_test_vect = vect.transform(X_test)\n",
        "\n",
        "# Ajustar el ensamble\n",
        "ensemble.fit(X_train_vect, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gK7rBOwNIYoM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-Score: 0.8866686257224018\n"
          ]
        }
      ],
      "source": [
        "# Predicciones del ensamble\n",
        "y_pred = ensemble.predict(X_test_vect)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcxwdm8bJ_Ez"
      },
      "source": [
        "### Conjunto Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZsWxY2MEKA3A"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    negativo\n",
              "2     60002    negativo\n",
              "3     60003    negativo\n",
              "4     60004    negativo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    positivo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conjunto_test = conjunto_test.set_index(conjunto_test['ID'])\n",
        "X_conjunto_test = vect.transform(conjunto_test['review_es'])\n",
        "\n",
        "pred_test = ensemble.predict(X_conjunto_test)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Q3n_RrKWH8"
      },
      "source": [
        "### Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WRWLYzJ_KYh-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/Ensamble_voting_2024-06-15.joblib']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Ensamble_voting_{current_date}.csv\", index=False)\n",
        "\n",
        "joblib.dump(ensemble, f'Modelos/Ensamble_voting_{current_date}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intentamos con redes neuronales unicamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creacion de nuestro propio classifier para soportar las redes neuronales\n",
        "class KerasVotingClassifier:\n",
        "    def __init__(self, models, weights=None):\n",
        "        self.models = models\n",
        "        self.weights = weights if weights is not None else [1] * len(models)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_train_list, X_test, y_test):\n",
        "        for model in self.models:\n",
        "            # Debemos adaptar la capa de vectorizacion de nuevo\n",
        "            text_vectorization_layer = model.layers[0]\n",
        "            text_vectorization_layer.adapt(X_train_list)\n",
        "\n",
        "            # Esos metodos de regularizacion nos permiten mejorar el modelo\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
        "            callbacks_list = [early_stopping, reduce_lr]\n",
        "\n",
        "            model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=[F1Score])\n",
        "            model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=callbacks_list)\n",
        "    \n",
        "    def predict(self, X, X_list=None):\n",
        "        prediction_list = []\n",
        "        for model in self.models :\n",
        "            # Debemos adaptar la capa de vectorizacion de nuevo para predecir\n",
        "            text_vectorization_layer = model.layers[0]\n",
        "            text_vectorization_layer.adapt(X_list)\n",
        "            prediction_list.append(model.predict(X))\n",
        "        \n",
        "        predictions = np.array(prediction_list)\n",
        "\n",
        "        # Votacion por promedio\n",
        "        avg_predictions = (np.average(predictions, axis=0, weights=self.weights) > 0.4).astype(int)\n",
        "        \n",
        "        return avg_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Modelos sin lematizacion\n",
        "models = [\n",
        "    load_model('Modelos/red_neuronal_2024-06-11.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-14.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-17.h5')\n",
        "]\n",
        "\n",
        "# Modelos con lematizacion\n",
        "models_lemm = [\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_1_dense_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-17.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_1_dense_2024-06-22.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_dense_2024-06-17.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_dense_2024-06-18.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_hiperparametros_2024-06-18.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_recurrent_2024-06-23.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-25.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_2_dense_2024-06-24.h5')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformacion en lista\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "X_train_lemm_list = X_train_processed.tolist()\n",
        "X_test_lemm_list = X_test_processed.tolist()\n",
        "\n",
        "# Transformacion en array\n",
        "X_train_array = np.array(X_train_list, dtype=object).reshape(-1,1)\n",
        "X_test_array = np.array(X_test_list, dtype=object).reshape(-1,1)\n",
        "X_train_lemm_array = np.array(X_train_lemm_list, dtype=object).reshape(-1,1)\n",
        "X_test_lemm_array = np.array(X_test_lemm_list, dtype=object).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - f1_score: 0.6626 - loss: 0.6802 - val_f1_score: 0.6711 - val_loss: 0.7282 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6670 - loss: 0.7440 - val_f1_score: 0.6720 - val_loss: 0.7852 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6699 - loss: 0.7366 - val_f1_score: 0.6722 - val_loss: 0.8163 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6663 - loss: 0.7515 - val_f1_score: 0.6712 - val_loss: 0.7615 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6636 - loss: 0.5569 - val_f1_score: 0.6705 - val_loss: 0.4323 - learning_rate: 1.0000e-03\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6672 - loss: 0.3645 - val_f1_score: 0.6703 - val_loss: 0.4088 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6678 - loss: 0.3647 - val_f1_score: 0.6702 - val_loss: 0.4037 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6613 - loss: 0.3618 - val_f1_score: 0.6703 - val_loss: 0.4120 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6651 - loss: 0.3670 - val_f1_score: 0.6702 - val_loss: 0.4055 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - f1_score: 0.6629 - loss: 0.3632 - val_f1_score: 0.6703 - val_loss: 0.4091 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6635 - loss: 0.3319 - val_f1_score: 0.6702 - val_loss: 0.3823 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6632 - loss: 0.3156 - val_f1_score: 0.6702 - val_loss: 0.3751 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6628 - loss: 0.3102 - val_f1_score: 0.6702 - val_loss: 0.3727 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6687 - loss: 0.3080 - val_f1_score: 0.6702 - val_loss: 0.3705 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6658 - loss: 0.3076 - val_f1_score: 0.6702 - val_loss: 0.3693 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6647 - loss: 0.3078 - val_f1_score: 0.6702 - val_loss: 0.3698 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6658 - loss: 0.3091 - val_f1_score: 0.6702 - val_loss: 0.3695 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6661 - loss: 0.3084 - val_f1_score: 0.6702 - val_loss: 0.3678 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - f1_score: 0.6617 - loss: 0.3060 - val_f1_score: 0.6702 - val_loss: 0.3698 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - f1_score: 0.6642 - loss: 0.3070 - val_f1_score: 0.6702 - val_loss: 0.3684 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - f1_score: 0.6689 - loss: 0.8408 - val_f1_score: 0.6701 - val_loss: 0.6187 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6715 - loss: 0.6588 - val_f1_score: 0.6701 - val_loss: 0.6401 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6701 - loss: 0.6525 - val_f1_score: 0.6701 - val_loss: 0.6450 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6661 - loss: 0.6787 - val_f1_score: 0.6701 - val_loss: 0.6419 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6637 - loss: 0.5122 - val_f1_score: 0.6701 - val_loss: 0.4433 - learning_rate: 1.0000e-03\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6650 - loss: 0.4218 - val_f1_score: 0.6701 - val_loss: 0.4382 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6646 - loss: 0.4146 - val_f1_score: 0.6701 - val_loss: 0.4439 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6696 - loss: 0.4077 - val_f1_score: 0.6701 - val_loss: 0.4365 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6636 - loss: 0.4013 - val_f1_score: 0.6701 - val_loss: 0.4341 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6660 - loss: 0.4047 - val_f1_score: 0.6701 - val_loss: 0.4444 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - f1_score: 0.6661 - loss: 0.4006 - val_f1_score: 0.6701 - val_loss: 0.4364 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - f1_score: 0.6700 - loss: 0.3990 - val_f1_score: 0.6701 - val_loss: 0.4427 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6642 - loss: 0.3609 - val_f1_score: 0.6701 - val_loss: 0.3953 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - f1_score: 0.6649 - loss: 0.3251 - val_f1_score: 0.6701 - val_loss: 0.3847 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - f1_score: 0.6630 - loss: 0.3105 - val_f1_score: 0.6701 - val_loss: 0.3843 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6675 - loss: 0.3049 - val_f1_score: 0.6701 - val_loss: 0.3820 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6626 - loss: 0.3015 - val_f1_score: 0.6701 - val_loss: 0.3817 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6674 - loss: 0.2968 - val_f1_score: 0.6701 - val_loss: 0.3842 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6659 - loss: 0.2941 - val_f1_score: 0.6701 - val_loss: 0.3850 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6656 - loss: 0.2942 - val_f1_score: 0.6701 - val_loss: 0.3881 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - f1_score: 0.6690 - loss: 0.7680 - val_f1_score: 0.6701 - val_loss: 0.6734 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - f1_score: 0.6644 - loss: 0.6770 - val_f1_score: 0.6701 - val_loss: 0.6394 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - f1_score: 0.6660 - loss: 0.6603 - val_f1_score: 0.6701 - val_loss: 0.7501 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 59ms/step - f1_score: 0.6651 - loss: 0.6596 - val_f1_score: 0.6701 - val_loss: 0.6250 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 58ms/step - f1_score: 0.6622 - loss: 0.6668 - val_f1_score: 0.6701 - val_loss: 0.6580 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 62ms/step - f1_score: 0.6670 - loss: 0.6676 - val_f1_score: 0.6701 - val_loss: 0.6860 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - f1_score: 0.6693 - loss: 0.6738 - val_f1_score: 0.6701 - val_loss: 0.6412 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 62ms/step - f1_score: 0.6646 - loss: 0.5067 - val_f1_score: 0.6701 - val_loss: 0.4442 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - f1_score: 0.6627 - loss: 0.4106 - val_f1_score: 0.6701 - val_loss: 0.4266 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - f1_score: 0.6600 - loss: 0.3966 - val_f1_score: 0.6701 - val_loss: 0.4311 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - f1_score: 0.6633 - loss: 0.3892 - val_f1_score: 0.6701 - val_loss: 0.4269 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - f1_score: 0.6699 - loss: 0.3906 - val_f1_score: 0.6701 - val_loss: 0.4371 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 62ms/step - f1_score: 0.6660 - loss: 0.3469 - val_f1_score: 0.6701 - val_loss: 0.3946 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - f1_score: 0.6664 - loss: 0.3185 - val_f1_score: 0.6701 - val_loss: 0.3859 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 58ms/step - f1_score: 0.6637 - loss: 0.3082 - val_f1_score: 0.6701 - val_loss: 0.3833 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 83ms/step - f1_score: 0.6695 - loss: 0.3054 - val_f1_score: 0.6701 - val_loss: 0.3828 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 72ms/step - f1_score: 0.6658 - loss: 0.3013 - val_f1_score: 0.6701 - val_loss: 0.3838 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - f1_score: 0.6672 - loss: 0.2947 - val_f1_score: 0.6701 - val_loss: 0.3863 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 58ms/step - f1_score: 0.6650 - loss: 0.2926 - val_f1_score: 0.6701 - val_loss: 0.3886 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - f1_score: 0.6658 - loss: 0.2808 - val_f1_score: 0.6701 - val_loss: 0.3837 - learning_rate: 4.0000e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 23ms/step - f1_score: 0.6666 - loss: 0.9963 - val_f1_score: 0.6701 - val_loss: 0.7577 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - f1_score: 0.6626 - loss: 0.7641 - val_f1_score: 0.6701 - val_loss: 0.7311 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - f1_score: 0.6659 - loss: 0.7779 - val_f1_score: 0.6701 - val_loss: 0.7899 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - f1_score: 0.6655 - loss: 0.8010 - val_f1_score: 0.6701 - val_loss: 0.7681 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - f1_score: 0.6620 - loss: 0.7933 - val_f1_score: 0.6701 - val_loss: 0.7977 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - f1_score: 0.6659 - loss: 0.5619 - val_f1_score: 0.6701 - val_loss: 0.4643 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - f1_score: 0.6668 - loss: 0.4332 - val_f1_score: 0.6701 - val_loss: 0.4713 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - f1_score: 0.6654 - loss: 0.4265 - val_f1_score: 0.6701 - val_loss: 0.4693 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - f1_score: 0.6692 - loss: 0.4129 - val_f1_score: 0.6701 - val_loss: 0.4780 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - f1_score: 0.6630 - loss: 0.3677 - val_f1_score: 0.6701 - val_loss: 0.4022 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - f1_score: 0.6649 - loss: 0.3037 - val_f1_score: 0.6701 - val_loss: 0.3909 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - f1_score: 0.6638 - loss: 0.2831 - val_f1_score: 0.6701 - val_loss: 0.3860 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - f1_score: 0.6650 - loss: 0.2781 - val_f1_score: 0.6701 - val_loss: 0.3856 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - f1_score: 0.6663 - loss: 0.2711 - val_f1_score: 0.6701 - val_loss: 0.3886 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 26ms/step - f1_score: 0.6659 - loss: 0.2665 - val_f1_score: 0.6701 - val_loss: 0.3909 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6679 - loss: 0.2648 - val_f1_score: 0.6702 - val_loss: 0.3944 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - f1_score: 0.6671 - loss: 0.2511 - val_f1_score: 0.6701 - val_loss: 0.3898 - learning_rate: 4.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - f1_score: 0.6622 - loss: 0.2479 - val_f1_score: 0.6701 - val_loss: 0.3880 - learning_rate: 4.0000e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - f1_score: 0.6640 - loss: 0.6776 - val_f1_score: 0.6709 - val_loss: 0.6877 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - f1_score: 0.6663 - loss: 0.7229 - val_f1_score: 0.6714 - val_loss: 0.8167 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - f1_score: 0.6638 - loss: 0.7390 - val_f1_score: 0.6710 - val_loss: 0.7063 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - f1_score: 0.6664 - loss: 0.7107 - val_f1_score: 0.6712 - val_loss: 0.7035 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6686 - loss: 0.5444 - val_f1_score: 0.6704 - val_loss: 0.4157 - learning_rate: 1.0000e-03\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6715 - loss: 0.3568 - val_f1_score: 0.6702 - val_loss: 0.3898 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - f1_score: 0.6658 - loss: 0.3546 - val_f1_score: 0.6702 - val_loss: 0.4052 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6669 - loss: 0.3481 - val_f1_score: 0.6703 - val_loss: 0.4011 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6648 - loss: 0.3479 - val_f1_score: 0.6702 - val_loss: 0.4058 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6618 - loss: 0.3245 - val_f1_score: 0.6702 - val_loss: 0.3758 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6680 - loss: 0.3072 - val_f1_score: 0.6702 - val_loss: 0.3652 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6686 - loss: 0.3013 - val_f1_score: 0.6702 - val_loss: 0.3613 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - f1_score: 0.6642 - loss: 0.3001 - val_f1_score: 0.6702 - val_loss: 0.3595 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - f1_score: 0.6637 - loss: 0.3004 - val_f1_score: 0.6702 - val_loss: 0.3584 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - f1_score: 0.6708 - loss: 0.3004 - val_f1_score: 0.6702 - val_loss: 0.3589 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - f1_score: 0.6673 - loss: 0.2979 - val_f1_score: 0.6702 - val_loss: 0.3585 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6661 - loss: 0.2988 - val_f1_score: 0.6702 - val_loss: 0.3651 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - f1_score: 0.6679 - loss: 0.2926 - val_f1_score: 0.6702 - val_loss: 0.3568 - learning_rate: 4.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - f1_score: 0.6679 - loss: 0.2910 - val_f1_score: 0.6702 - val_loss: 0.3571 - learning_rate: 4.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - f1_score: 0.6687 - loss: 0.2921 - val_f1_score: 0.6702 - val_loss: 0.3564 - learning_rate: 4.0000e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - f1_score: 0.6625 - loss: 0.8488 - val_f1_score: 0.6701 - val_loss: 0.6538 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.6641 - loss: 0.6505 - val_f1_score: 0.6701 - val_loss: 0.6690 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - f1_score: 0.6676 - loss: 0.6523 - val_f1_score: 0.6701 - val_loss: 0.6148 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - f1_score: 0.6681 - loss: 0.6407 - val_f1_score: 0.6701 - val_loss: 0.6358 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.6640 - loss: 0.6585 - val_f1_score: 0.6701 - val_loss: 0.6568 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - f1_score: 0.6674 - loss: 0.6475 - val_f1_score: 0.6701 - val_loss: 0.6251 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.6673 - loss: 0.4900 - val_f1_score: 0.6701 - val_loss: 0.4230 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - f1_score: 0.6640 - loss: 0.3974 - val_f1_score: 0.6701 - val_loss: 0.4230 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 21ms/step - f1_score: 0.6664 - loss: 0.3969 - val_f1_score: 0.6701 - val_loss: 0.4259 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - f1_score: 0.6703 - loss: 0.3844 - val_f1_score: 0.6701 - val_loss: 0.4258 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - f1_score: 0.6629 - loss: 0.3481 - val_f1_score: 0.6701 - val_loss: 0.3818 - learning_rate: 2.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - f1_score: 0.6610 - loss: 0.3086 - val_f1_score: 0.6701 - val_loss: 0.3735 - learning_rate: 2.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - f1_score: 0.6685 - loss: 0.2984 - val_f1_score: 0.6701 - val_loss: 0.3705 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6662 - loss: 0.2899 - val_f1_score: 0.6701 - val_loss: 0.3743 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6653 - loss: 0.2858 - val_f1_score: 0.6701 - val_loss: 0.3778 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - f1_score: 0.6625 - loss: 0.2845 - val_f1_score: 0.6701 - val_loss: 0.3758 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - f1_score: 0.6663 - loss: 0.2727 - val_f1_score: 0.6701 - val_loss: 0.3715 - learning_rate: 4.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - f1_score: 0.6656 - loss: 0.2709 - val_f1_score: 0.6701 - val_loss: 0.3705 - learning_rate: 4.0000e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 203ms/step - f1_score: 0.6695 - loss: 1.2741 - val_f1_score: 0.6701 - val_loss: 0.9593 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 173ms/step - f1_score: 0.6700 - loss: 0.8604 - val_f1_score: 0.6701 - val_loss: 0.7355 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 192ms/step - f1_score: 0.6621 - loss: 0.8290 - val_f1_score: 0.6702 - val_loss: 0.8890 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 181ms/step - f1_score: 0.6719 - loss: 0.8108 - val_f1_score: 0.6701 - val_loss: 0.8238 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 133ms/step - f1_score: 0.6655 - loss: 0.7887 - val_f1_score: 0.6701 - val_loss: 0.8712 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 132ms/step - f1_score: 0.6676 - loss: 0.5629 - val_f1_score: 0.6701 - val_loss: 0.4607 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 130ms/step - f1_score: 0.6670 - loss: 0.4197 - val_f1_score: 0.6702 - val_loss: 0.4563 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 126ms/step - f1_score: 0.6676 - loss: 0.4062 - val_f1_score: 0.6702 - val_loss: 0.4668 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 147ms/step - f1_score: 0.6676 - loss: 0.4044 - val_f1_score: 0.6702 - val_loss: 0.4539 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 165ms/step - f1_score: 0.6659 - loss: 0.3932 - val_f1_score: 0.6702 - val_loss: 0.4599 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 185ms/step - f1_score: 0.6690 - loss: 0.3964 - val_f1_score: 0.6702 - val_loss: 0.4482 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 171ms/step - f1_score: 0.6671 - loss: 0.3875 - val_f1_score: 0.6702 - val_loss: 0.4478 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 145ms/step - f1_score: 0.6673 - loss: 0.3865 - val_f1_score: 0.6703 - val_loss: 0.4507 - learning_rate: 1.0000e-03\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 144ms/step - f1_score: 0.6690 - loss: 0.3798 - val_f1_score: 0.6702 - val_loss: 0.4569 - learning_rate: 1.0000e-03\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 118ms/step - f1_score: 0.6658 - loss: 0.3887 - val_f1_score: 0.6703 - val_loss: 0.4460 - learning_rate: 1.0000e-03\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 117ms/step - f1_score: 0.6665 - loss: 0.3827 - val_f1_score: 0.6703 - val_loss: 0.4467 - learning_rate: 1.0000e-03\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 117ms/step - f1_score: 0.6646 - loss: 0.3870 - val_f1_score: 0.6703 - val_loss: 0.4554 - learning_rate: 1.0000e-03\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 121ms/step - f1_score: 0.6696 - loss: 0.3917 - val_f1_score: 0.6703 - val_loss: 0.4528 - learning_rate: 1.0000e-03\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 137ms/step - f1_score: 0.6628 - loss: 0.3414 - val_f1_score: 0.6703 - val_loss: 0.3942 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 137ms/step - f1_score: 0.6667 - loss: 0.2959 - val_f1_score: 0.6703 - val_loss: 0.3808 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - f1_score: 0.6690 - loss: 0.7747 - val_f1_score: 0.6707 - val_loss: 0.8243 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - f1_score: 0.6660 - loss: 0.8884 - val_f1_score: 0.6704 - val_loss: 0.9059 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6649 - loss: 0.9355 - val_f1_score: 0.6716 - val_loss: 0.8278 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6678 - loss: 0.9414 - val_f1_score: 0.6715 - val_loss: 0.7756 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - f1_score: 0.6660 - loss: 0.9039 - val_f1_score: 0.6709 - val_loss: 0.8224 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6689 - loss: 0.9214 - val_f1_score: 0.6709 - val_loss: 0.8168 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6662 - loss: 0.9152 - val_f1_score: 0.6712 - val_loss: 0.8100 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - f1_score: 0.6672 - loss: 0.7090 - val_f1_score: 0.6706 - val_loss: 0.4413 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - f1_score: 0.6680 - loss: 0.4482 - val_f1_score: 0.6703 - val_loss: 0.4002 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - f1_score: 0.6632 - loss: 0.4135 - val_f1_score: 0.6702 - val_loss: 0.4000 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6679 - loss: 0.4182 - val_f1_score: 0.6703 - val_loss: 0.4276 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - f1_score: 0.6690 - loss: 0.4226 - val_f1_score: 0.6702 - val_loss: 0.3981 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - f1_score: 0.6654 - loss: 0.4220 - val_f1_score: 0.6703 - val_loss: 0.4100 - learning_rate: 1.0000e-03\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - f1_score: 0.6613 - loss: 0.4218 - val_f1_score: 0.6701 - val_loss: 0.3990 - learning_rate: 1.0000e-03\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - f1_score: 0.6671 - loss: 0.4191 - val_f1_score: 0.6703 - val_loss: 0.4009 - learning_rate: 1.0000e-03\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - f1_score: 0.6657 - loss: 0.3894 - val_f1_score: 0.6702 - val_loss: 0.3789 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6669 - loss: 0.3611 - val_f1_score: 0.6702 - val_loss: 0.3663 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - f1_score: 0.6668 - loss: 0.3536 - val_f1_score: 0.6702 - val_loss: 0.3621 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - f1_score: 0.6640 - loss: 0.3500 - val_f1_score: 0.6702 - val_loss: 0.3598 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - f1_score: 0.6693 - loss: 0.3502 - val_f1_score: 0.6702 - val_loss: 0.3576 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 51ms/step - f1_score: 0.6661 - loss: 1.4333 - val_f1_score: 0.6701 - val_loss: 1.1834 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 48ms/step - f1_score: 0.6644 - loss: 1.3772 - val_f1_score: 0.6701 - val_loss: 1.3098 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 48ms/step - f1_score: 0.6666 - loss: 1.3185 - val_f1_score: 0.6701 - val_loss: 1.1440 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 47ms/step - f1_score: 0.6687 - loss: 1.2169 - val_f1_score: 0.6701 - val_loss: 1.1529 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - f1_score: 0.6664 - loss: 1.2253 - val_f1_score: 0.6701 - val_loss: 1.4135 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6637 - loss: 1.2501 - val_f1_score: 0.6701 - val_loss: 1.1393 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - f1_score: 0.6676 - loss: 1.1842 - val_f1_score: 0.6701 - val_loss: 1.0706 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - f1_score: 0.6666 - loss: 1.1868 - val_f1_score: 0.6701 - val_loss: 1.0760 - learning_rate: 0.0050\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - f1_score: 0.6657 - loss: 1.1864 - val_f1_score: 0.6701 - val_loss: 0.9750 - learning_rate: 0.0050\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - f1_score: 0.6649 - loss: 1.1393 - val_f1_score: 0.6701 - val_loss: 1.0505 - learning_rate: 0.0050\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - f1_score: 0.6654 - loss: 1.1277 - val_f1_score: 0.6701 - val_loss: 1.1534 - learning_rate: 0.0050\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - f1_score: 0.6670 - loss: 1.1673 - val_f1_score: 0.6701 - val_loss: 1.1028 - learning_rate: 0.0050\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - f1_score: 0.6687 - loss: 0.8036 - val_f1_score: 0.6701 - val_loss: 0.6198 - learning_rate: 1.0000e-03\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - f1_score: 0.6639 - loss: 0.6763 - val_f1_score: 0.6701 - val_loss: 0.6062 - learning_rate: 1.0000e-03\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 37ms/step - f1_score: 0.6702 - loss: 0.6682 - val_f1_score: 0.6701 - val_loss: 0.6062 - learning_rate: 1.0000e-03\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - f1_score: 0.6646 - loss: 0.6604 - val_f1_score: 0.6701 - val_loss: 0.6141 - learning_rate: 1.0000e-03\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - f1_score: 0.6664 - loss: 0.6568 - val_f1_score: 0.6701 - val_loss: 0.6136 - learning_rate: 1.0000e-03\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6645 - loss: 0.5758 - val_f1_score: 0.6701 - val_loss: 0.4600 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - f1_score: 0.6632 - loss: 0.4583 - val_f1_score: 0.6701 - val_loss: 0.4293 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6644 - loss: 0.4290 - val_f1_score: 0.6701 - val_loss: 0.4237 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - f1_score: 0.6677 - loss: 1.0492 - val_f1_score: 0.6701 - val_loss: 0.9648 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - f1_score: 0.6699 - loss: 1.0121 - val_f1_score: 0.6701 - val_loss: 0.8722 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - f1_score: 0.6663 - loss: 1.0077 - val_f1_score: 0.6701 - val_loss: 0.8713 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - f1_score: 0.6681 - loss: 0.9632 - val_f1_score: 0.6701 - val_loss: 0.8811 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - f1_score: 0.6708 - loss: 0.9698 - val_f1_score: 0.6701 - val_loss: 0.8834 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6655 - loss: 0.9817 - val_f1_score: 0.6701 - val_loss: 0.8513 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6666 - loss: 0.9668 - val_f1_score: 0.6701 - val_loss: 0.9233 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - f1_score: 0.6621 - loss: 0.9892 - val_f1_score: 0.6701 - val_loss: 0.8989 - learning_rate: 0.0050\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - f1_score: 0.6663 - loss: 0.9641 - val_f1_score: 0.6701 - val_loss: 0.9529 - learning_rate: 0.0050\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - f1_score: 0.6667 - loss: 0.7373 - val_f1_score: 0.6701 - val_loss: 0.5536 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - f1_score: 0.6639 - loss: 0.6231 - val_f1_score: 0.6701 - val_loss: 0.5448 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.6681 - loss: 0.6228 - val_f1_score: 0.6701 - val_loss: 0.5473 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - f1_score: 0.6696 - loss: 0.6175 - val_f1_score: 0.6701 - val_loss: 0.5387 - learning_rate: 1.0000e-03\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - f1_score: 0.6650 - loss: 0.6086 - val_f1_score: 0.6701 - val_loss: 0.5532 - learning_rate: 1.0000e-03\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6684 - loss: 0.6163 - val_f1_score: 0.6701 - val_loss: 0.5499 - learning_rate: 1.0000e-03\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6616 - loss: 0.6098 - val_f1_score: 0.6701 - val_loss: 0.5526 - learning_rate: 1.0000e-03\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - f1_score: 0.6605 - loss: 0.5566 - val_f1_score: 0.6701 - val_loss: 0.4441 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - f1_score: 0.6655 - loss: 0.4635 - val_f1_score: 0.6701 - val_loss: 0.4093 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - f1_score: 0.6665 - loss: 0.4336 - val_f1_score: 0.6701 - val_loss: 0.4019 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - f1_score: 0.6656 - loss: 0.4277 - val_f1_score: 0.6701 - val_loss: 0.3992 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - f1_score: 0.6683 - loss: 0.9552 - val_f1_score: 0.6701 - val_loss: 0.9265 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - f1_score: 0.6639 - loss: 0.8199 - val_f1_score: 0.6701 - val_loss: 0.7848 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 46ms/step - f1_score: 0.6653 - loss: 0.7828 - val_f1_score: 0.6701 - val_loss: 0.8069 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6663 - loss: 0.7576 - val_f1_score: 0.6702 - val_loss: 0.7408 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 45ms/step - f1_score: 0.6632 - loss: 0.7461 - val_f1_score: 0.6701 - val_loss: 0.7416 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - f1_score: 0.6646 - loss: 0.7526 - val_f1_score: 0.6701 - val_loss: 0.7841 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 46ms/step - f1_score: 0.6644 - loss: 0.7413 - val_f1_score: 0.6701 - val_loss: 0.7142 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6675 - loss: 0.7175 - val_f1_score: 0.6701 - val_loss: 0.7222 - learning_rate: 0.0050\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 53ms/step - f1_score: 0.6609 - loss: 0.7194 - val_f1_score: 0.6701 - val_loss: 0.7343 - learning_rate: 0.0050\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 50ms/step - f1_score: 0.6652 - loss: 0.7278 - val_f1_score: 0.6701 - val_loss: 0.7108 - learning_rate: 0.0050\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 44ms/step - f1_score: 0.6650 - loss: 0.7277 - val_f1_score: 0.6701 - val_loss: 0.6976 - learning_rate: 0.0050\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - f1_score: 0.6647 - loss: 0.7223 - val_f1_score: 0.6701 - val_loss: 0.7779 - learning_rate: 0.0050\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 47ms/step - f1_score: 0.6660 - loss: 0.7185 - val_f1_score: 0.6701 - val_loss: 0.7719 - learning_rate: 0.0050\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 46ms/step - f1_score: 0.6646 - loss: 0.7178 - val_f1_score: 0.6701 - val_loss: 0.7435 - learning_rate: 0.0050\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6664 - loss: 0.5373 - val_f1_score: 0.6701 - val_loss: 0.4628 - learning_rate: 1.0000e-03\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - f1_score: 0.6684 - loss: 0.4161 - val_f1_score: 0.6701 - val_loss: 0.4567 - learning_rate: 1.0000e-03\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 48ms/step - f1_score: 0.6679 - loss: 0.4076 - val_f1_score: 0.6701 - val_loss: 0.4478 - learning_rate: 1.0000e-03\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - f1_score: 0.6687 - loss: 0.3993 - val_f1_score: 0.6701 - val_loss: 0.4473 - learning_rate: 1.0000e-03\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 57ms/step - f1_score: 0.6627 - loss: 0.3913 - val_f1_score: 0.6701 - val_loss: 0.4408 - learning_rate: 1.0000e-03\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 49ms/step - f1_score: 0.6697 - loss: 0.3955 - val_f1_score: 0.6701 - val_loss: 0.4601 - learning_rate: 1.0000e-03\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - f1_score: 0.6688 - loss: 0.4426 - val_f1_score: 0.6702 - val_loss: 0.3372 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - f1_score: 0.6709 - loss: 0.3663 - val_f1_score: 0.6701 - val_loss: 0.3454 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6685 - loss: 0.3280 - val_f1_score: 0.6708 - val_loss: 0.3166 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 26ms/step - f1_score: 0.6705 - loss: 0.3087 - val_f1_score: 0.6720 - val_loss: 0.3139 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6749 - loss: 0.2976 - val_f1_score: 0.6709 - val_loss: 0.3264 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - f1_score: 0.6732 - loss: 0.2920 - val_f1_score: 0.6725 - val_loss: 0.3171 - learning_rate: 0.0050\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 26ms/step - f1_score: 0.6768 - loss: 0.2875 - val_f1_score: 0.6719 - val_loss: 0.3216 - learning_rate: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - f1_score: 0.6747 - loss: 0.2576 - val_f1_score: 0.6721 - val_loss: 0.3058 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - f1_score: 0.6758 - loss: 0.2556 - val_f1_score: 0.6731 - val_loss: 0.3050 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6746 - loss: 0.2414 - val_f1_score: 0.6723 - val_loss: 0.3057 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - f1_score: 0.6747 - loss: 0.2334 - val_f1_score: 0.6729 - val_loss: 0.3082 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - f1_score: 0.6697 - loss: 0.2265 - val_f1_score: 0.6738 - val_loss: 0.3160 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - f1_score: 0.6789 - loss: 0.2184 - val_f1_score: 0.6736 - val_loss: 0.3084 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - f1_score: 0.6750 - loss: 0.2217 - val_f1_score: 0.6737 - val_loss: 0.3090 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 43ms/step - f1_score: 0.6647 - loss: 1.2769 - val_f1_score: 0.6701 - val_loss: 1.2347 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - f1_score: 0.6659 - loss: 1.2990 - val_f1_score: 0.6701 - val_loss: 1.0741 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - f1_score: 0.6681 - loss: 1.2185 - val_f1_score: 0.6701 - val_loss: 1.2215 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - f1_score: 0.6660 - loss: 1.2494 - val_f1_score: 0.6701 - val_loss: 1.1106 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - f1_score: 0.6655 - loss: 1.2124 - val_f1_score: 0.6701 - val_loss: 1.1976 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - f1_score: 0.6652 - loss: 0.7819 - val_f1_score: 0.6701 - val_loss: 0.6003 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - f1_score: 0.6662 - loss: 0.6116 - val_f1_score: 0.6701 - val_loss: 0.5831 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - f1_score: 0.6653 - loss: 0.6081 - val_f1_score: 0.6701 - val_loss: 0.5914 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - f1_score: 0.6668 - loss: 0.6103 - val_f1_score: 0.6701 - val_loss: 0.5986 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - f1_score: 0.6672 - loss: 0.6075 - val_f1_score: 0.6701 - val_loss: 0.5788 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 24ms/step - f1_score: 0.6634 - loss: 0.6019 - val_f1_score: 0.6701 - val_loss: 0.5944 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - f1_score: 0.6705 - loss: 0.6046 - val_f1_score: 0.6701 - val_loss: 0.5832 - learning_rate: 1.0000e-03\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - f1_score: 0.6650 - loss: 0.6052 - val_f1_score: 0.6701 - val_loss: 0.5953 - learning_rate: 1.0000e-03\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - f1_score: 0.6646 - loss: 0.5358 - val_f1_score: 0.6701 - val_loss: 0.4299 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - f1_score: 0.6634 - loss: 0.4032 - val_f1_score: 0.6701 - val_loss: 0.4074 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - f1_score: 0.6644 - loss: 0.3791 - val_f1_score: 0.6701 - val_loss: 0.4023 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6679 - loss: 0.3698 - val_f1_score: 0.6701 - val_loss: 0.4009 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6666 - loss: 0.3654 - val_f1_score: 0.6701 - val_loss: 0.4043 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - f1_score: 0.6709 - loss: 0.3642 - val_f1_score: 0.6701 - val_loss: 0.4044 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.6666 - loss: 0.3631 - val_f1_score: 0.6701 - val_loss: 0.4059 - learning_rate: 2.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 22ms/step - f1_score: 0.6664 - loss: 0.3468 - val_f1_score: 0.6712 - val_loss: 0.3291 - learning_rate: 0.0050\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - f1_score: 0.6706 - loss: 0.2209 - val_f1_score: 0.6729 - val_loss: 0.3253 - learning_rate: 0.0050\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - f1_score: 0.6841 - loss: 0.1606 - val_f1_score: 0.6795 - val_loss: 0.3699 - learning_rate: 0.0050\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.6911 - loss: 0.1128 - val_f1_score: 0.6947 - val_loss: 0.4633 - learning_rate: 0.0050\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - f1_score: 0.7048 - loss: 0.1013 - val_f1_score: 0.7075 - val_loss: 0.4654 - learning_rate: 0.0050\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - f1_score: 0.7079 - loss: 0.0707 - val_f1_score: 0.7095 - val_loss: 0.5102 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 53ms/step - f1_score: 0.7297 - loss: 0.0578 - val_f1_score: 0.7127 - val_loss: 0.5430 - learning_rate: 1.0000e-03\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step\n",
            "Accuracy: 0.8776\n",
            "Precision: 0.847260149280903\n",
            "Recall: 0.923595951577694\n",
            "F1 Score: 0.8837827573110522\n",
            "Accuracy - Lematizacion: 0.8864\n",
            "Precision - Lematizacion: 0.8532126696832579\n",
            "Recall - Lematizacion: 0.9355030760071443\n",
            "F1 Score - Lematizacion: 0.8924649753881106\n"
          ]
        }
      ],
      "source": [
        "# Utilizamos los F1-Score de Kaggle para ponderar los modelos\n",
        "f1_scores = {\n",
        "    'keras1': 0.76584,\n",
        "    'keras2': 0.75789,\n",
        "    'keras3': 0.75770,\n",
        "    'keras4': 0.75596\n",
        "}\n",
        "\n",
        "f1_scores_lemm = {\n",
        "    'keras1': 0.77263,\n",
        "    'keras2': 0.75751,\n",
        "    'keras3': 0.76371,\n",
        "    'keras4': 0.77863,\n",
        "    'keras5': 0.74704,\n",
        "    'keras6': 0.76235,\n",
        "    'keras7': 0.75247,\n",
        "    'keras8': 0.77127,\n",
        "    'keras9': 0.76584,\n",
        "    'keras10': 0.72669\n",
        "}\n",
        "\n",
        "# Normalizacion de los pesos\n",
        "total_f1 = sum(f1_scores.values())\n",
        "initial_weights = [score / total_f1 for score in f1_scores.values()]\n",
        "\n",
        "total_f1_lemm = sum(f1_scores_lemm.values())\n",
        "initial_weights_lemm = [score / total_f1_lemm for score in f1_scores_lemm.values()]\n",
        "\n",
        "# Creacion del ensamble\n",
        "voting_classifier = KerasVotingClassifier(models=models, weights=initial_weights)\n",
        "voting_classifier.fit(X_train_array, y_train, X_train_list, X_test_array, y_test)\n",
        "\n",
        "voting_classifier_lemm = KerasVotingClassifier(models=models_lemm, weights=initial_weights_lemm)\n",
        "voting_classifier_lemm.fit(X_train_lemm_array, y_train, X_train_lemm_list, X_test_lemm_array, y_test)\n",
        "\n",
        "# Predicciones del ensamble\n",
        "y_pred_avg = voting_classifier.predict(X_test_array, X_train_list)\n",
        "y_pred_avg_lemm = voting_classifier_lemm.predict(X_test_lemm_array, X_train_lemm_list)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = accuracy_score(y_test, y_pred_avg)\n",
        "precision = precision_score(y_test, y_pred_avg)\n",
        "recall = recall_score(y_test, y_pred_avg)\n",
        "f1 = f1_score(y_test, y_pred_avg)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "accuracy_lemm = accuracy_score(y_test, y_pred_avg_lemm)\n",
        "precision_lemm = precision_score(y_test, y_pred_avg_lemm)\n",
        "recall_lemm = recall_score(y_test, y_pred_avg_lemm)\n",
        "f1_lemm = f1_score(y_test, y_pred_avg_lemm)\n",
        "\n",
        "print(f'Accuracy - Lematizacion: {accuracy_lemm}')\n",
        "print(f'Precision - Lematizacion: {precision_lemm}')\n",
        "print(f'Recall - Lematizacion: {recall_lemm}')\n",
        "print(f'F1 Score - Lematizacion: {f1_lemm}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# Transformacion de los conjuntos de test\n",
        "conjunto_test_index = conjunto_test.set_index(conjunto_test['ID'])\n",
        "X_conjunto_test = conjunto_test_index['review_es']\n",
        "X_conjunto_test_list = X_conjunto_test.tolist()\n",
        "\n",
        "X_conjunto_test_lemm = conjunto_test_processed\n",
        "X_conjunto_test_list_lemm = X_conjunto_test_lemm.tolist()\n",
        "\n",
        "# Predicciones con y sin lematizacion\n",
        "pred_test_avg = voting_classifier.predict(X_conjunto_test, X_conjunto_test_list)\n",
        "pred_test_avg_lemm = voting_classifier_lemm.predict(X_conjunto_test_lemm, X_conjunto_test_list_lemm)\n",
        "\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test_avg]\n",
        "pred_test_labels_lemm = ['positivo' if pred == 1 else 'negativo' for pred in pred_test_avg_lemm]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df_lemm = pd.DataFrame({\n",
        "    'ID': conjunto_test_processed.index,\n",
        "    'sentimiento': pred_test_labels_lemm\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportacion del modelo y de las predicciones\n",
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Ensamble_voting_redes_neuronales_{current_date}.csv\", index=False)\n",
        "final_pred_df_lemm.to_csv(f\"Predicciones/Ensamble_voting_redes_neuronales_lematizacion_{current_date}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creacion del ensamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tomando los ultimos y los mejores (que no es el ultimo) de cada modelo\n",
        "\n",
        "ultimo_nb_model = joblib.load('Modelos/bn_model_2024-06-15.joblib')\n",
        "mejor_nb_model = joblib.load('Modelos/bn_model_2024-05-31.joblib')\n",
        "\n",
        "# Aca tenemos problemas con ese parametro cuando cargamos el modelo, asi ponemos True cada vez\n",
        "if hasattr(ultimo_nb_model, 'force_alpha') and ultimo_nb_model.force_alpha not in [True, False]:\n",
        "    ultimo_nb_model.force_alpha = True\n",
        "if hasattr(mejor_nb_model, 'force_alpha') and mejor_nb_model.force_alpha not in [True, False]:\n",
        "    mejor_nb_model.force_alpha = True\n",
        "\n",
        "ultimo_xgb_model = joblib.load('Modelos/xgb_model_2024-06-15.joblib')\n",
        "mejor_xgb_model = joblib.load('Modelos/xgb_model_2024-05-28.joblib')\n",
        "\n",
        "ultimo_rf_model = joblib.load('Modelos/rf_model_2024-06-15.joblib')\n",
        "mejor_rf_model = joblib.load('Modelos/rf_model_2024-06-15.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vectorizacion de los conjuntos\n",
        "vect = TfidfVectorizer(stop_words=stop_words_es, min_df=2, ngram_range=(1,3))\n",
        "\n",
        "X_train_vect = vect.fit_transform(X_train).astype('float32')\n",
        "X_test_vect = vect.transform(X_test).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-Score: 0.8994176290593229\n"
          ]
        }
      ],
      "source": [
        "# Lista de nuestros modelos\n",
        "base_models = [\n",
        "    ('ultimo nb', ultimo_nb_model),\n",
        "    ('mejor nb', mejor_nb_model),\n",
        "    ('ultimo xgb', ultimo_xgb_model),\n",
        "    ('mejor xgb', mejor_xgb_model),\n",
        "    ('ultimo rf', ultimo_rf_model),\n",
        "    ('mejor rf', mejor_rf_model),\n",
        "]\n",
        "\n",
        "base_predictions_train = np.zeros((X_train_vect.shape[0], len(base_models)))\n",
        "base_predictions_test = np.zeros((X_test_vect.shape[0], len(base_models)))\n",
        "\n",
        "# Por cada modelo, predecimos los resultados\n",
        "for i, (name, model) in enumerate(base_models):\n",
        "    model.fit(X_train_vect, y_train)\n",
        "    base_predictions_train[:, i] = cross_val_predict(model, X_train_vect, y_train, cv=5, method='predict_proba')[:, 1]\n",
        "    base_predictions_test[:, i] = model.predict_proba(X_test_vect)[:, 1]\n",
        "\n",
        "# Meta-aprendizaje con LogisticRegression\n",
        "meta_learner = LogisticRegression(random_state=42)\n",
        "meta_learner.fit(base_predictions_train, y_train)\n",
        "\n",
        "final_predictions = meta_learner.predict(base_predictions_test)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "precision = precision_score(y_test, final_predictions)\n",
        "recall = recall_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8594</th>\n",
              "      <td>68594</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>68595</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8596</th>\n",
              "      <td>68596</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>68597</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8598</th>\n",
              "      <td>68598</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID sentimiento\n",
              "0     60000    negativo\n",
              "1     60001    negativo\n",
              "2     60002    negativo\n",
              "3     60003    negativo\n",
              "4     60004    negativo\n",
              "...     ...         ...\n",
              "8594  68594    positivo\n",
              "8595  68595    negativo\n",
              "8596  68596    positivo\n",
              "8597  68597    negativo\n",
              "8598  68598    negativo\n",
              "\n",
              "[8599 rows x 2 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conjunto_test = conjunto_test.set_index(conjunto_test['ID'])\n",
        "X_conjunto_test = vect.transform(conjunto_test['review_es'])\n",
        "\n",
        "base_predictions_conjunto_test = np.zeros((X_conjunto_test.shape[0], len(base_models)))\n",
        "\n",
        "for i, (name, model) in enumerate(base_models):\n",
        "    base_predictions_conjunto_test[:, i] = model.predict_proba(X_conjunto_test)[:, 1]\n",
        "\n",
        "pred_test = meta_learner.predict(base_predictions_conjunto_test)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exportaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/Ensamble_stacking_2024-06-16.joblib']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Ensamble_stacking_{current_date}.csv\", index=False)\n",
        "\n",
        "joblib.dump(meta_learner, f'Modelos/Ensamble_stacking_{current_date}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intentamos con redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creacion de nuestro propio classifier para soportar las redes neuronales\n",
        "class KerasStackingClassifier:\n",
        "    def __init__(self, models, weights=None):\n",
        "        self.models = models\n",
        "        self.weights = weights if weights is not None else [1] * len(models)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_train_list):\n",
        "        # Meta-aprendizaje con LogisticRegression\n",
        "        self.meta_learner = LogisticRegression(random_state=42)\n",
        "        self.base_predictions_train = np.zeros((X_train.shape[0], len(self.models)))\n",
        "        \n",
        "        for i, model in enumerate(self.models):\n",
        "            # Debemos adaptar la capa de vectorizacion de nuevo\n",
        "            text_vectorization_layer = model.layers[0]\n",
        "            text_vectorization_layer.adapt(X_train_list)\n",
        "            self.base_predictions_train[:, i] = model.predict(X_train).flatten()\n",
        "\n",
        "        # Optimizacion del LogisticRegression\n",
        "        param_grid = {\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'solver': ['lbfgs', 'liblinear'],\n",
        "            'penalty': ['l1', 'l2']\n",
        "        }\n",
        "        grid_search = GridSearchCV(self.meta_learner, param_grid, cv=5, scoring='f1')\n",
        "        grid_search.fit(self.base_predictions_train, y_train)\n",
        "        \n",
        "        self.meta_learner = grid_search.best_estimator_\n",
        "        self.meta_learner.fit(self.base_predictions_train, y_train)\n",
        "\n",
        "    def predict(self, X_test, X_test_list):\n",
        "        base_predictions_test = np.zeros((X_test.shape[0], len(self.models)))\n",
        "        \n",
        "        for i, model in enumerate(self.models):\n",
        "            # Debemos adaptar la capa de vectorizacion de nuevo\n",
        "            text_vectorization_layer = model.layers[0]\n",
        "            text_vectorization_layer.adapt(X_test_list)\n",
        "            base_predictions_test[:, i] = model.predict(X_test).flatten()\n",
        "\n",
        "        final_predictions = self.meta_learner.predict(base_predictions_test)\n",
        "        return final_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Modelos sin lematizacion\n",
        "models = [\n",
        "    load_model('Modelos/red_neuronal_2024-06-11.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-14.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_2024-06-17.h5')\n",
        "]\n",
        "\n",
        "# Modelos con lematizacion\n",
        "models_lemm = [\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_1_dense_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-15.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-17.h5')\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_1_dense_2024-06-22.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_dense_2024-06-17.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_dense_2024-06-18.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_hiperparametros_2024-06-18.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_recurrent_2024-06-23.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_2024-06-25.h5'),\n",
        "    load_model('Modelos/red_neuronal_lemmarizacion_dropout_2_dense_2024-06-24.h5')\n",
        "]\n",
        "\n",
        "# Transformacion en lista\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "X_train_lemm_list = X_train_processed.tolist()\n",
        "X_test_lemm_list = X_test_processed.tolist()\n",
        "\n",
        "# Transformacion en array\n",
        "X_train_array = np.array(X_train_list, dtype=object).reshape(-1,1)\n",
        "X_test_array = np.array(X_test_list, dtype=object).reshape(-1,1)\n",
        "X_train_lemm_array = np.array(X_train_lemm_list, dtype=object).reshape(-1,1)\n",
        "X_test_lemm_array = np.array(X_test_lemm_list, dtype=object).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "25 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.9481758  0.94107312 0.94162656        nan 0.96524911\n",
            " 0.95521357 0.95573665        nan 0.96725895 0.96450258 0.96460786\n",
            "        nan 0.96745724 0.96696372 0.96696372        nan 0.96745898\n",
            " 0.9674347  0.9674347 ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "25 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\flaph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.97217487 0.96803382 0.9704727         nan 0.98625091\n",
            " 0.98068048 0.9810418         nan 0.98882606 0.98632335 0.98634878\n",
            "        nan 0.98940198 0.98837405 0.98837405        nan 0.98955188\n",
            " 0.98965264 0.98965262]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "F1-Score: 0.8714159030446349\n",
            "F1-Score - Lemm: 0.8756799525269509\n"
          ]
        }
      ],
      "source": [
        "# Creacion del ensamble\n",
        "stacking_classifier = KerasStackingClassifier(models=models)\n",
        "stacking_classifier.fit(X_train_array, y_train, X_train_list)\n",
        "\n",
        "stacking_classifier_lemm = KerasStackingClassifier(models=models_lemm)\n",
        "stacking_classifier_lemm.fit(X_train_lemm_array, y_train, X_train_lemm_list)\n",
        "\n",
        "# Predicciones del ensamble\n",
        "final_predictions = stacking_classifier.predict(X_test_array, X_test_list)\n",
        "final_predictions_lemm = stacking_classifier_lemm.predict(X_test_lemm_array, X_test_lemm_list)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "precision = precision_score(y_test, final_predictions)\n",
        "recall = recall_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "accuracy_lemm = accuracy_score(y_test, final_predictions_lemm)\n",
        "precision_lemm = precision_score(y_test, final_predictions_lemm)\n",
        "recall_lemm = recall_score(y_test, final_predictions_lemm)\n",
        "f1_lemm = f1_score(y_test, final_predictions_lemm)\n",
        "\n",
        "print(f'Accuracy - Lematizacion: {accuracy_lemm}')\n",
        "print(f'Precision - Lematizacion: {precision_lemm}')\n",
        "print(f'Recall - Lematizacion: {recall_lemm}')\n",
        "print(f'F1 Score - Lematizacion: {f1_lemm}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Transformacion de los conjuntos de test\n",
        "conjunto_test_index = conjunto_test.set_index(conjunto_test['ID'])\n",
        "X_conjunto_test = conjunto_test_index['review_es']\n",
        "X_conjunto_test_list = X_conjunto_test.tolist()\n",
        "X_conjunto_test_array = np.array(X_conjunto_test_list, dtype=object).reshape(-1, 1)\n",
        "\n",
        "X_conjunto_test_lemm = conjunto_test_processed\n",
        "X_conjunto_test_list_lemm = X_conjunto_test_lemm.tolist()\n",
        "X_conjunto_test_array_lemm = np.array(X_conjunto_test_list_lemm, dtype=object).reshape(-1, 1)\n",
        "\n",
        "# Predicciones con y sin lematizacion\n",
        "pred_test = stacking_classifier.predict(X_conjunto_test_array, X_conjunto_test_list)\n",
        "pred_test_labels = ['positivo' if pred == 1 else 'negativo' for pred in pred_test]\n",
        "\n",
        "pred_test_lemm = stacking_classifier_lemm.predict(X_conjunto_test_array_lemm, X_conjunto_test_list_lemm)\n",
        "pred_test_labels_lemm = ['positivo' if pred == 1 else 'negativo' for pred in pred_test_lemm]\n",
        "\n",
        "# Transformacion en DataFrame para respetar las consignas\n",
        "final_pred_df = pd.DataFrame({\n",
        "    'ID': conjunto_test.index,\n",
        "    'sentimiento': pred_test_labels\n",
        "})\n",
        "final_pred_df_lemm = pd.DataFrame({\n",
        "    'ID': conjunto_test_processed.index,\n",
        "    'sentimiento': pred_test_labels_lemm\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Modelos/Ensamble_stacking_redes_neuronales_lemmatizacion_2024-06-24.joblib']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exportacion del modelo y de las predicciones\n",
        "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "final_pred_df.to_csv(f\"Predicciones/Ensamble_stacking_redes_neuronales_{current_date}.csv\", index=False)\n",
        "joblib.dump(stacking_classifier.meta_learner, f'Modelos/Ensamble_stacking_redes_neuronales_{current_date}.joblib')\n",
        "\n",
        "final_pred_df_lemm.to_csv(f\"Predicciones/Ensamble_stacking_redes_neuronales_lemmatizacion_{current_date}.csv\", index=False)\n",
        "joblib.dump(stacking_classifier_lemm.meta_learner, f'Modelos/Ensamble_stacking_redes_neuronales_lemmatizacion_{current_date}.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
